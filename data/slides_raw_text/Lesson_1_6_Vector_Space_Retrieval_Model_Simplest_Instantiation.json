{
    "0": "1\n \nVector Space Model: Simplest Instantiation\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n",
    "1": "Course Schedule\n \n2\n \nBig Text Data\n \nSmall Relevant Data\n \n  \nSearch Engine\n \nRecommender \n \nSystem\n \n2. Text Access\n \n11. Recommendation\n \n3. Text Retrieval Problem\n \n10. Web Search\n \nUser\n \n1. Natural Language Content Analysis\n \n4. Text Retrieval Methods\n \n7. Evaluation \n \n6. System \n \nImplementation\n \n5. Vector Space Model\n \n8. Probabilistic Model \n \n9. Feedback  \n \n",
    "2": "3\n \n\nS\nay\n \n?\n \n?\n \n?\n \nd=(\ny\n1\n\ny\nN\n), \ny\nj\n=?\n \nq\n=(\nx\n1\n\nN\n), \nx\ni\n=?\n  \n \nSim(\nq\n,\nd\n)=?\n \n \n",
    "3": "4\n \nDimension Instantiation: Bag of Words (BOW)\n \nw\n3\n \nw\n2\n \nw\n1\n \nVocabulary V=(\nw\n1\n, \n\nw\nN\n)\n \n",
    "4": "5\n \nVector Placement: Bit Vector\n \nw\n3\n \nw\n2\n \nw\n1\n \nd=(\ny\n1\n\ny\nN\n)\n \n \nq\n=(\nx\n1\n\nN\n)\n \nx\ni,\n, \ny\ni\n \n\n{0,1}\n \n \n1\n: word W\ni\n \nis \npresent\n \n0\n: \nword W\ni\n \nis \nabsent\n \n \n",
    "5": "6\n \nSimilarity Instantiation: Dot Product\n \nd=(\ny\n1\n\ny\nN\n)\n \nq\n=(\nx\n1\n\nN\n)\n \nSim(\nq\n,\nd\n)=\nq\n.\nd\n= \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \nw\n1\n \nw\n2\n \nw\n3\n \n",
    "6": "Simplest VSM= Bit\n-\nVector + Dot\n-\nProduct + BOW\n \n7\n \nWhat does this ranking function intuitively capture? \n \nIs \nthis a good ranking function? \n \nx\ni,\n, \ny\ni\n \n\n{0,1}\n \n \n1\n: word W\ni\n \nis \npresent\n \n0\n: \nword W\ni\n \nis \nabsent\n \n \nSim(\nq\n,\nd\n)=\nq\n.\nd\n= \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \nq=(\nx\n1\n\nN\n)\n \nd=(\ny\n1\n\ny\nN\n)\n \n",
    "7": "An Example: How W\nould You Rank These Documents?\n \n8\n \n\nnews about presidential campaign\n\n \n\nnews about \n\n \nd\n1\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \n\nnews\n \nof \npresidential campaign \n\n \n\npresidential \n\n \nd\n4\n \n\nnews\n \nof organic food \ncampaign\n\ncampaign\n\ncampaign\n\ncampaign\n\n \nd\n5\n \nd\n4\n \nd\n3\n \n \n \nd1\n \nd\n2\n \nd\n5\n \n \n+\n \n+\n \n \n \n-\n \n-\n \n-\n \n \nIdeal Ranking?\n \n",
    "8": "Ranking Using the Simplest VSM\n \n9\n \n\nnews about presidential campaign\n\n \n\nnews about \n\n \nd\n1\n \nV= {\nnews,   about,   presidential,  campaign,  food \n\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \nd1= (1,         1,              0,                 \n0\n,              0\n, \n   \n\n \nd3= (1,         0,              \n1\n,                 1,              0\n, \n   \n\n \n\n \n\n \n",
    "9": "Is the Simplest VSM Effective? \n \n10\n \n\n \n\nnews about \n\n \nd\n1\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \n\nnews\n \nof \npresidential campaign \n\n \n\npresidential \n\n \nd\n4\n \n\nnews\n \nof organic food \ncampaign\n\ncampaign\n\ncampaign\n\ncampaign\n\n \nd\n5\n \nf(q,d1\n)=2\n \nf(q,d2)=\n3\n \nf(q,d3)=\n3\n \nf(q,d4)=\n3\n \nf(q,d5)=2\n \n",
    "10": "Summary\n \n\nVSM instantiation: dimension, vector placement, \nsimilarity\n \n \n\nSimplest VSM\n \n\nDimension = word\n \n\nVector = 0\n-\n1 bit vector (word presence/absence)\n \n\nSimilarity = dot product\n \n\nf(\nq,d\n) = number of \ndistinct\n \nquery words matched in d \n \n11\n \n"
}