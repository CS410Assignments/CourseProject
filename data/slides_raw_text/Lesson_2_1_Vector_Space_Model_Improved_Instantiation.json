{
    "0": "Vector Space Model: Improved Instantiation\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n1\n \n",
    "1": "Course Schedule\n \n2\n \nBig Text Data\n \nSmall Relevant Data\n \n  \nSearch Engine\n \nRecommender \n \nSystem\n \n2. Text Access\n \n11. Recommendation\n \n3. Text Retrieval Problem\n \n10. Web Search\n \nUser\n \n1. Natural Language Content Analysis\n \n4. Text Retrieval Methods\n \n7. Evaluation \n \n6. System \n \nImplementation\n \n5. Vector Space Model\n \n8. Probabilistic Model \n \n9. Feedback  \n \n",
    "2": "Two Problems of the Simplest VSM\n \n\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \n\nnews\n \nof \npresidential campaign \n\n \n\npresidential \n\n \nd\n4\n \nf(q,d2)=\n3\n \nf(q,d3)=\n3\n \nf(q,d4)=\n3\n \n\npresidential\n\n \n\npresidential\n\nabout\n\n \n3\n \n",
    "3": "Improved Vector Placement\n: Term Frequency Vector\n \nw\n3\n \nw\n2\n \nw\n1\n \nd=(\ny\n1\n\ny\nN\n)\n \n \nq\n=(\nx\n1\n\nN\n)\n \nx\ni\n \n= count of word \nW\ni \nin \nquery\n \ny\ni\n \n= count of word \nW\ni \nin \ndoc\n \n4\n \n",
    "4": "Improved VSM with Term Frequency Weighting \n \nSim(\nq\n,\nd\n)=\nq\n.\nd\n= \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \nq=(\nx\n1\n\nN\n)\n \nd=(\ny\n1\n\ny\nN\n)\n \nx\ni\n \n= count of word \nW\ni \nin \nquery\n \ny\ni\n \n= count of word \nW\ni \nin \ndoc\n \nWhat does this ranking function intuitively capture?  \n \n \nDoes it fix the problems of the simplest VSM?\n \n5\n \n",
    "5": "Ranking Using Term Frequency (TF) Weighting\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \nd2= (1,         1,              0,                 \n1\n\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \n\nnews\n \nof \npresidential campaign \n\n \n\npresidential \n\n \nd\n4\n \nf(q,d2)=\n3\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \nd4= (1,         \n0\n,              \n2\n,                 \n1\n,              0\n, \n   \n\n \nf(q,d4)=4!\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \nd3= (1,         0,              \n1\n,                 \n1\n,              0\n, \n   \n\n \nf(q,d3)=\n3\n \n6\n \n",
    "6": "\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \nd2= (1,         1,              0,                 \n1\n\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \nq\n= (1,         1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \nd3= (1,         0,              \n1\n,                 \n1\n,              0\n, \n   \n\n \nf(q,d2)<3\n \nf(q,d3)>3\n \nV= {\nnews,   about,   presidential,  campaign,  food \n\n \n7\n \n",
    "7": "Further Improvement of Vector Placement: \n \nAdding Inverse Document Frequency (IDF)\n \nw\n3\n \nw\n2\n \nw\n1\n \nd=(\ny\n1\n\ny\nN\n)\n \n \nq\n=(\nx\n1\n\nN\n)\n \nx\ni\n \n= \ncount of word \nW\ni \nin query\n \ny\ni\n \n= \nc(\nW\ni \n,d) *\nIDF(\nW\ni\n)\n \n8\n \n",
    "8": "IDF Weighting: Penalizing Popular Terms\n \nIDF(W)\n \nk (doc \nfreq\n)\n \nIDF(W) \n= \nlog[(M+1)/k\n]\n \nM\n \n \n1\n \nlog(M+1)\n \ntotal \nnumber of docs in collection\n \ntotal \nnumber of docs \ncontaining W\n \n(Doc Frequency)\n \n9\n \n",
    "9": "q\n= (1,                  1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \nd2= (1*1.5,         \n1*1.0\n          \n0,                 1*3.1,       0\n, \n   \n\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \nq\n= (1,                  1,              1\n, \n                \n1\n, \n             \n0\n, \n   \n\n \nd3= (1*1.5,           0,              \n1*2.5\n           \n1*3.1,       0\n, \n   \n\n \nV= {\nnews,         about,    presidential,  campaign,  food \n\n \n\n \nIDF(W)= 1.5                1.0            2.5              3.1              1.8\n \nf(q,d2) = 5.6    <    f(q,d3)=7.1\n \n10\n \n",
    "10": "How Effective Is VSM with TF\n-\nIDF Weighting? \n \n\n \n\nnews about \n\n \nd\n1\n \n\nnews about \norganic food \ncampaign\n\n \nd\n2\n \n\nnews\n \nof \npresidential campaign \n\n \nd\n3\n \n\nnews\n \nof \npresidential campaign \n\n \n\npresidential \n\n \nd\n4\n \n\nnews\n \nof organic food \ncampaign\n\ncampaign\n\ncampaign\n\ncampaign\n\n \nd\n5\n \nf(q,d1\n)=2.5\n \nf(q,d2)=5.6\n \nf(q,d3)=7.1\n \nf(q,d4)=9.6\n \nf(q,d5)=13.9!\n \n11\n \n",
    "11": "Summary\n \n\nImproved VSM\n \n\nDimension = word\n \n\nVector = TF\n-\nIDF weight vector\n \n\nSimilarity = dot product\n \n\nWorking better than the simplest VSM\n \n\nStill having problems\n \n \n12\n \n"
}