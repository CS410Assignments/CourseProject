{
    "0": "Probabilistic Retrieval Model: Query \nLilkelihood\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n1\n \n",
    "1": "2\n \nBig Text Data\n \nSmall Relevant Data\n \n  \nSearch Engine\n \nRecommender \n \nSystem\n \n2. Text Access\n \n8. Recommendation\n \n3. Text Retrieval Problem\n \n7. Web Search\n \nUser\n \n1. Natural Language Content Analysis\n \n4. Text Retrieval Methods\n \n5. Evaluation \n \n6. System \n \nImplementation\n \n4.3 Probabilistic Model\n \nProbabilistic Retrieval Model: Query Likelihood\n \n",
    "2": "Query Generation by Sampling Words from Doc  \n \n3\n \np(q= \n\n\n|\nd\n=\n \n\nnews\n \nof \npresidential \ncampaign \n\npresidential \n\n \n)\n \n\n \ncampaign \n \nIf the user is \nthinking of this doc \n, \n \nhow likely would she \npose this query\n? \n \n",
    "3": "Unigram Query Likelihood   \n \n4\n \np(q= \n\n\n|\nd\n=\n \n\nnews\n \nof \npresidential \ncampaign \n\npresidential \n\n \n)\n \n=  p(\n\n|d)*p(\n\n|d)\n \nAssumption\n:\n \nEach query word is generated independently\n \n",
    "4": "Does Query Likelihood Make Sense?    \n \n5\n \np(q|d4=  \n                                              \n)\n \n\npresidential campaign \n\npresidential \n\n \n\ncampaign\n\n \n\npresidential campaign \n\n \np(q|d2=                                        \n)\n \np(q|d3=   \n                                              \n)\n \n=\n\n\n\n\n\n\n\n\n\n \n=\n\n\n\n\n\n\n\n\n\n \n=\n\n\n\n\n\n\n\n\n\n=0\n \nd4> d3 > d2 \nas we expected\n \n",
    "5": "Try a Different Query?    \n \n6\n \np(q|d4=  \n                                               \n)\n \n\npresidential campaign \n\npresidential \n\n \n\ncampaign\n\n \n\npresidential campaign \n\n \np(q|d2\n=                                       \n)\n \np(q|d3=                                                  \n)\n \n=\n\n\n\n\n\n\n\n\n\n\n=0!\n \n=\n\n\n\n\n\n\n\n\n\n \n\n\n\n=0!\n \n=\n\n\n\n\n\n\n\n\n\n\n\n\n=0\n \nWhat assumption has caused this problem? How do we fix it? \n \nq \n\npresidential campaign \nupdate\n\n \n",
    "6": "Improved Model: Sampling Words from a \nDoc Model  \n \n7\n \np(q= \n\n\n|\nd\n=\n \n\nnews\n \nof \npresidential \ncampaign \n\npresidential \n\n \n)\n \nHow likely would we observe \nthis query\n \nfrom \nthis doc model\n? \n \n\n \npresidential\n  \n0.2\n \ncampaign\n \n0.1\n \nnews 0.01\n \ncandidate 0.02\n \n\n \nupdate 0.00001\n \n\n \n\n \ncampaign \n \nupdate \n \n",
    "7": "Computation of Query Likelihood\n \n \n \n8\n \n \nDocument\n \nQuery q \n= \n \n\n \n \nd1\n \n \nd2\n \np\n\ndata mining alg\n\n)\n \n  \n=    p\n\n\n \n     \n\n \np\n\n\n \n     \n\n \np\n\n\n)\n \nFood nutrition\n \npaper\n \nText mining\n \npaper\n \n\n \ntext  0.2\n \nmining 0.1\n \nassociation 0.01\n \nclustering 0.02\n \n\n \nfood\n \n0.00001\n \n\n \n\n \nfood 0.25\n \nnutrition 0.1\n \nhealthy 0.05\n \ndiet 0.02\n \n\n \n \nDocument LM\n \np(w|d1)\n \n \np(w|d2)\n \np\n\ndata mining alg\n\n \n  \n=    p\n\n\n \n     \n\n \np\n\n\n \n     \n\n \np\n\n\n \n",
    "8": "9\n \nSummary\n: Ranking based on Query Likelihood\n \nDocument language model\n \nRetrieval  problem   \n\n \nEstimation of \np(\nw\ni\n|d\n)\n \n \nDifferent estimation methods \n\n \ndifferent ranking functions\n \n"
}