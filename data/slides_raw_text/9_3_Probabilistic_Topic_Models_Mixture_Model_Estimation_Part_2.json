{
    "0": "Probabilistic Topic Models: \n \nMixture Model Estimation \n \n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n1\n \n",
    "1": "Probabilistic Topic Models: \n \nMixture Model Estimation\n \n2\n \nReal World\n \nObserved World\n \nText Data\n \n(English)\n \nPerceive\n \nExpress\n \n(Perspective)\n \n3. Topic mining & analysis\n \n4. Opinion mining and \n \n \n   \nsentiment analysis\n \n5\n. Text\n-\nbased prediction\n \n1.\nNatural language \nprocessing  & text \nrepresentation\n \n3. Topic mining and analysis\n \n5\n. Text\n-\nbased prediction\n \n1.\nNatural language \nprocessing and text \nrepresentation\n \n2. Word association \nmining and analysis\n \n",
    "2": "Back to Factoring out Background \nW\nords  \n \n3\n \ntext  0.04\n \nmining \n0.035\n \nassociation 0.03\n \nclustering \n0.005\n \n\n \nthe\n \n0.000001\n \n\nd\n \n \nthe 0.03\n \na 0.02\n \nis 0.015\n \nwe \n0.01\n \nfood \n0.003\n \n\n \ntext  0.000006\n \n\nB\n \nP(\n\nd\n)=0.5\n \nP(\n\nB\n)=0.5\n \nTopic \n \nChoice\n \np(\n\nd \n)+(\n\nB\n)=1\n \n\ntext mining...\n \ni\n\nclustering\n\n\nText.. \nthe\n \n \n \nText Mining Paper\n \n \n             \nd\n \n",
    "3": "Estimation of One Topic\n: \nP(w|\n \n\nd\n)\n \n4\n \ntext  ?\n \nmining \n?\n \nassociation \n?\n \nclustering \n?\n \n\n \nthe\n \n?\n \n\nd\n \n \nthe 0.03\n \na 0.02\n \nis 0.015\n \nwe \n0.01\n \nfood \n0.003\n \n\n \ntext  0.000006\n \n\nB\n \nP(\n\nd\n)=0.5\n \nP(\n\nB\n)=0.5\n \nTopic \n \nChoice\n \np(\n\nd \n)+(\n\nB\n)=1\n \n\ntext mining...\n \ni\n\nclustering\n\n\nText.. \nthe\n \n \n \nd\n \nAdjust\n \n\nd\nto\n \nmaximize p(d|\n\n)\n \n(all other parameters are known)\n \nWould the ML estimate \ndemote\n \n \nbackground words in \n\nd\n \n?\n \n",
    "4": "Behavior of a Mixture Model \n \n5\n \n \ntext \nthe\n \n \nd\n \n= \n \nLikelihood:\n \n\np(\n\nd\n\n\nd\n) \n+ \np\n(\n\nB\n\n\nB\n)\n \n               \n= \n\n\n\nd\n) \n+0.5*0.1\n \n\n \n\n\nd\n) \n+0.5*0.9\n \ntext  ?\n \nthe\n \n?\n \n\nd\n \n \nthe \n0.9\n \ntext  0.1\n \n\nB\n \nP(\n\nd\n)=0.5\n \nP(\n\nB\n)=0.5\n \np(d|\n\n\n\n)\n \n\n\n\n)\n \n=\n \n[\n\n\n\nd\n) \n+ 0.5*0.1] x\n \n \n  \n[\n0.5*p\n\n\nd\n) \n+ 0.5*0.9]\n \nHow can we set \np\n\n\nd\n)\n  \n& \n\n\nd\n) \nto maximize it? \n \n \n \nNote that  \np\n\n\nd\n)\n \n+ \n\n\n\nd\n) \n=1 \n \n \n",
    "5": "\n\nd\n \nand\n \n\nB\n \n6\n \n \ntext \nthe\n \n \nd\n \n= \n \np(d|\n\n\n\n)\n \n\n\n\n)\n \ntext  ?\n \nthe\n \n?\n \n\nd\n \n \nthe \n0.9\n \ntext  0.1\n \n\nB\n \nP(\n\nd\n)=0.5\n \nP(\n\nB\n)=0.5\n \n=\n \n[\n\n\n\nd\n) \n+ 0.5*0.1] x\n \n \n  \n[\n0.5*p\n\n\nd\n) \n+ 0.5*0.9]\n \n \nNote that  \np\n\n\nd\n)\n \n+ \n\n\n\nd\n) \n=1 \n \n \nIf \n\n\n\n\n\n,  then \n\n \nreaches maximum when \n\n\n\n\n \n0.5*p\n\n\nd\n) \n+ \n0.5*0.1= \n0.5*p\n\n\nd\n) \n+ \n0.5*0.9\n \n \n\n \np\n\n\nd\n)=0.9    \n>>     p\n\n\nd\n) \n=0.1 !\n \nBehavior 1\n:\n \nif p(w1|\n\nB\n)> \np(w2|\n\nB\n), then \np(w1|\n\nd\n) < \np(w2|\n\nd\n)\n \n",
    "6": "Response to Data Frequency\n \n7\n \n \ntext \nthe\n \n \nd\n \n= \n \np(d|\n\n) = \n\n\n\nd\n) \n+ 0.5*0.1] \n \n \n                \nx [0.5*p\n\n\nd\n) \n+ 0.5*0.9]\n \n\n \np\n\n\nd\n)=0.9    \n>>     p\n\n\nd\n) \n=0.1 !\n \n \ntext \nthe \nthe\n \nthe\n \nthe\n \n\n \n \nd\n\n \n   \n\n\nd\n) + 0.5*0.9]\n \n\n\n) = \n\n\n\nd\n) \n+ 0.5*0.1] \n \n \n                \nx [0.5*p\n\n\nd\n) \n+ 0.5*0.9]\n \n   \n\n\nd\n) + 0.5*0.9]\n \n   \n\n\nd\n) + 0.5*0.9]\n \n\n \n\np\n\n\n\nd\n) \n> \n0.1\n? or \n\n\n\nd\n)  \n<\n \n0.1\n?   \n \nBehavior 2: \nhigh frequency words get higher\n  \np(w|\n\nd\n) \n \nWhat if we increase p(\n\nB\n)? \n \n",
    "7": "Summary\n \n\nGeneral behavior of a mixture model:\n \n\nEvery component model attempts to assign high probabilities to \n\n\n \n\n\n\n \n\n\ncollaboration/competition between the component models\n \n\nF\nixing one component to a background word distribution (i.e., \nbackground language model): \n \n\nH\n\n \n\nIs an example of imposing a prior on the model parameters (prior = \none model must be exactly the same as the background LM) \n \n8\n \n"
}