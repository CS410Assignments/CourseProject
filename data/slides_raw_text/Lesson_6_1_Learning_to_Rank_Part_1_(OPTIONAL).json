{
    "0": "Web Search: Learning to Rank\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n1\n \n",
    "1": "Web Search: Learning to Rank\n \n2\n \nBig Text Data\n \nSmall Relevant Data\n \n  \nSearch Engine\n \nRecommender \n \nSystem\n \n2. Text Access\n \n11. \nRecommendation\n \n3. Text Retrieval Problem\n \n10. \nWeb Search\n \nUser\n \n1. Natural Language Content Analysis\n \n4. Text Retrieval Methods\n \n7\n. \nEvaluation \n \n6. System \n \nImplementation\n \n5\n. Vector Space Model\n \n8\n. Probabilistic Model \n \n9. Feedback  \n \n",
    "2": "3\n \nHow Can \nW\ne \nC\nombine \nM\nany \nF\neatures? \n \n(Learning to Rank)\n \n\nGeneral idea:\n \n\nGiven a query\n-\ndoc pair (Q,D), define various kinds of features \nXi(Q,D)\n \n\nExamples of feature: the number of overlapping terms, BM25 \nscore of Q and D, p(Q|D), PageRank of D, p(\nQ|Di\n), where Di may \n\n \n\n\nXn\n(Q,D), \n\n) where \n\n \nis a \nset of parameters\n \n\nLearn \n\n \nby fitting function s with training data, i.e., 3\n-\ntuples like  \n(D, Q, 1) (D is relevant to Q) or (D,Q,0) (D is non\n-\nrelevant to Q) \n \n",
    "3": "4\n \nRegression\n-\nBased Approaches\n \nLogistic Regression: Xi(Q,D) is feature; \n\n\n \n \nEstimate \n\n\nt\nraining data\n \n \n                   \nX1(Q,D)      X2 (Q,D)     X3(Q,D) \n \n                   \nBM25         PageRank    BM25Anchor\n \nD1 (R=1)     0.7                  0.11             0.65\n \nD2 (R=0)      0.3                 0.05              0.4\n \n \nOnce \n\n\nnew document  to generate a score for D w.r.t. Q.\n \n",
    "4": "More Advanced Learning Algorithms\n \n\nAttempt to directly optimize a retrieval measure (e.g. \nMAP, \nnDCG\n)\n \n\nMore difficult as an optimization problem\n \n\nMany solutions were proposed [Liu 09]\n \n\nCan be applied to many other ranking problems beyond \nsearch\n \n\nRecommender systems\n \n\nComputational advertising\n \n\nSummarization \n \n\n\n \n \n5\n \n",
    "5": "Summary\n \n\nMachine learning has been applied to text retrieval since many \ndecades ago (e.g., \nRocchio\n \nfeedback) \n \n\nRecent use of machine learning is driven by \n \n\nLarge\n-\nscale training data available \n \n\nNeed for combining many features \n \n\nNeed for robust ranking (again spams) \n \n\nModern Web search engines all use some kind of ML technique \nto combine many features to optimize ranking \n \n\nLearning to rank is still an active research topic \n \n6\n \n",
    "6": "Additional Readings\n \n\nTie\n-\nYan \nLiu. Learning \nto Rank for Information Retrieval. \nFoundations and Trends in Information Retrieval \n3, 3 \n(2009): 225\n-\n331.\n \n\nHang Li. A Short \nI\nntroduction to Learning to Rank, IEICE \nTrans. Inf. & Syst. E94\n-\nD, 10 (Oct\n. \n2011): \nn.p\n.\n \n \n7\n \n"
}