{
    "0": "Web Search\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n1\n \n",
    "1": "Web Search\n \n2\n \nBig Text \nData\n \nSmall Relevant \nData\n \n  \nSearch Engine\n \nRecommender \n \nSystem\n \n2. Text Access\n \n8. Recommendation\n \n3. Text Retrieval Problem\n \n7. Web Search\n \nUser\n \n1. Natural Language Content Analysis\n \n4. Text Retrieval Methods\n \n6. System \n \nImplementation\n \n5. Evaluation\n \n",
    "2": "Web Search: Challenges & Opportunities\n \n\nChallenges\n \n\nScalability \n \n\nHow to handle the size of the Web and ensure completeness of \ncoverage?\n \n\nHow to serve many user queries quickly? \n \n\nLow quality information and spams\n \n\nDynamics of the Web\n \n\nNew pages are constantly created and some pages may be updated \nvery quickly\n \n\nOpportunities \n \n\nmany additional heuristics (\ne.g., \nlinks) can be leveraged to \nimprove search accuracy \n \n3\n \n\n \nParallel indexing & searching (\nMapReduce\n)\n \n\nSpam detection \n \n    \n& \nRobust \nranking\n \n\nLink \nanalysis & multi\n-\nfeature ranking\n \n",
    "3": "4\n \nBasic Search Engine Technologies\n \nCached\n \npages\n \nCrawler\n \nWeb\n \n----\n \n----\n \n\n \n----\n \n----\n \n----\n \n----\n \n\n \n----\n \n----\n \n\n \nIndexer\n \n(Inverted) Index\n \n\n \nRetriever\n \nBrowser\n \nQuery\n \nHost Info.\n \nResults\n \nUser\n \n",
    "4": "Component I: Crawler/Spider/Robot\n \n\n\n \n\n\n \n\nFetch pages from the web\n \n\nParse  fetched pages for hyperlinks; add them to the queue\n \n\nFollow the hyperlinks in the queue\n \n\n\n \n\nRobustness (server failure, trap, etc.)\n \n\nCrawling courtesy (server load balance, robot exclusion, etc.)\n \n\nHandling file types (images, PDF files, etc.)\n \n\nURL extensions (\ncgi\n \nscript, internal references, etc.)\n \n\nRecognize redundant pages (identical and duplicates)\n \n\n\n \n5\n \n",
    "5": "6\n \nMajor Crawling Strategies\n \n\nBreadth\n-\nFirst is common (balance server load)\n \n\nParallel crawling is natural \n \n\nVariation: focused crawling \n \n\n\n \n\nTypically given a query\n \n\nHow to find new pages (they may not linked to an old page!)\n \n\nIncremental/repeated crawling\n \n\nN\need to minimize resource overhead \n \n\nCan learn from the past experience (updated daily vs. monthly) \n \n\nTarget at : 1) frequently updated pages; 2) frequently accessed pages \n \n",
    "6": "Summary\n \n\nWeb search is one of the most important applications \nof text retrieval\n \n\nNew challenges: scalability, efficiency, quality of information\n \n\nNew opportunities: rich link information, layout, \netc\n \n\nCrawler is an essential component of Web search \napplications \n \n\nInitial crawling: complete vs. focused\n \n\nIncremental crawling: resource optimization \n \n7\n \n"
}