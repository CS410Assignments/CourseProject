{"id":"0704.0047","submitter":"Igor Grabec","authors":"T. Kosel and I. Grabec","title":"Intelligent location of simultaneously active acoustic emission sources:\n  Part I","comments":"5 pages, 5 eps figures, uses IEEEtran.cls","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  The intelligent acoustic emission locator is described in Part I, while Part\nII discusses blind source separation, time delay estimation and location of two\nsimultaneously active continuous acoustic emission sources.\n  The location of acoustic emission on complicated aircraft frame structures is\na difficult problem of non-destructive testing. This article describes an\nintelligent acoustic emission source locator. The intelligent locator comprises\na sensor antenna and a general regression neural network, which solves the\nlocation problem based on learning from examples. Locator performance was\ntested on different test specimens. Tests have shown that the accuracy of\nlocation depends on sound velocity and attenuation in the specimen, the\ndimensions of the tested area, and the properties of stored data. The location\naccuracy achieved by the intelligent locator is comparable to that obtained by\nthe conventional triangulation method, while the applicability of the\nintelligent locator is more general since analysis of sonic ray paths is\navoided. This is a promising method for non-destructive testing of aircraft\nframe structures by the acoustic emission method.\n","versions":[{"version":"v1","created":"Sun, 1 Apr 2007 13:06:50 GMT"}],"update_date":"2009-09-29","authors_parsed":[["Kosel","T.",""],["Grabec","I.",""]]}
{"id":"0704.0050","submitter":"Igor Grabec","authors":"T. Kosel and I. Grabec","title":"Intelligent location of simultaneously active acoustic emission sources:\n  Part II","comments":"5 pages, 7 eps figures, uses IEEEtran.cls","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  Part I describes an intelligent acoustic emission locator, while Part II\ndiscusses blind source separation, time delay estimation and location of two\ncontinuous acoustic emission sources.\n  Acoustic emission (AE) analysis is used for characterization and location of\ndeveloping defects in materials. AE sources often generate a mixture of various\nstatistically independent signals. A difficult problem of AE analysis is\nseparation and characterization of signal components when the signals from\nvarious sources and the mode of mixing are unknown. Recently, blind source\nseparation (BSS) by independent component analysis (ICA) has been used to solve\nthese problems. The purpose of this paper is to demonstrate the applicability\nof ICA to locate two independent simultaneously active acoustic emission\nsources on an aluminum band specimen. The method is promising for\nnon-destructive testing of aircraft frame structures by acoustic emission\nanalysis.\n","versions":[{"version":"v1","created":"Sun, 1 Apr 2007 18:53:13 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Kosel","T.",""],["Grabec","I.",""]]}
{"id":"0704.0304","submitter":"Carlos Gershenson","authors":"Carlos Gershenson","title":"The World as Evolving Information","comments":"16 pages. Extended version, three more laws of information, two\n  classifications, and discussion added. To be published (soon) in\n  International Conference on Complex Systems 2007 Proceedings","journal-ref":"Minai, A., Braha, D., and Bar-Yam, Y., eds. Unifying Themes in\n  Complex Systems VII, pp. 100-115. Springer, Berlin Heidelberg, 2012","doi":"10.1007/978-3-642-18003-3_10","report-no":null,"categories":"cs.IT cs.AI math.IT q-bio.PE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses the benefits of describing the world as information,\nespecially in the study of the evolution of life and cognition. Traditional\nstudies encounter problems because it is difficult to describe life and\ncognition in terms of matter and energy, since their laws are valid only at the\nphysical scale. However, if matter and energy, as well as life and cognition,\nare described in terms of information, evolution can be described consistently\nas information becoming more complex.\n  The paper presents eight tentative laws of information, valid at multiple\nscales, which are generalizations of Darwinian, cybernetic, thermodynamic,\npsychological, philosophical, and complexity principles. These are further used\nto discuss the notions of life, cognition and their evolution.\n","versions":[{"version":"v1","created":"Tue, 3 Apr 2007 02:08:48 GMT"},{"version":"v2","created":"Thu, 30 Aug 2007 20:03:59 GMT"},{"version":"v3","created":"Wed, 13 Oct 2010 19:49:16 GMT"}],"update_date":"2013-04-05","authors_parsed":[["Gershenson","Carlos",""]]}
{"id":"0704.0671","submitter":"Maxim Raginsky","authors":"Maxim Raginsky","title":"Learning from compressed observations","comments":"6 pages; submitted to the 2007 IEEE Information Theory Workshop (ITW\n  2007)","journal-ref":null,"doi":"10.1109/ITW.2007.4313111","report-no":null,"categories":"cs.IT cs.LG math.IT","license":null,"abstract":"  The problem of statistical learning is to construct a predictor of a random\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\npredictors are drawn from some specified class, and the goal is to approach\nasymptotically the performance (expected loss) of the best predictor in the\nclass. We consider the setting in which one has perfect observation of the\n$X$-part of the sample, while the $Y$-part has to be communicated at some\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\n$X$-values. Under suitable regularity conditions on the admissible predictors,\nthe underlying family of probability distributions and the loss function, we\ngive an information-theoretic characterization of achievable predictor\nperformance in terms of conditional distortion-rate functions. The ideas are\nillustrated on the example of nonparametric regression in Gaussian noise.\n","versions":[{"version":"v1","created":"Thu, 5 Apr 2007 02:57:15 GMT"}],"update_date":"2016-11-15","authors_parsed":[["Raginsky","Maxim",""]]}
{"id":"0704.0954","submitter":"Jos\\'e M. F. Moura","authors":"Soummya Kar and Jose M. F. Moura","title":"Sensor Networks with Random Links: Topology Design for Distributed\n  Consensus","comments":"Submitted to IEEE Transactions","journal-ref":null,"doi":"10.1109/TSP.2008.920143","report-no":null,"categories":"cs.IT cs.LG math.IT","license":null,"abstract":"  In a sensor network, in practice, the communication among sensors is subject\nto:(1) errors or failures at random times; (3) costs; and(2) constraints since\nsensors and networks operate under scarce resources, such as power, data rate,\nor communication. The signal-to-noise ratio (SNR) is usually a main factor in\ndetermining the probability of error (or of communication failure) in a link.\nThese probabilities are then a proxy for the SNR under which the links operate.\nThe paper studies the problem of designing the topology, i.e., assigning the\nprobabilities of reliable communication among sensors (or of link failures) to\nmaximize the rate of convergence of average consensus, when the link\ncommunication costs are taken into account, and there is an overall\ncommunication budget constraint. To consider this problem, we address a number\nof preliminary issues: (1) model the network as a random topology; (2)\nestablish necessary and sufficient conditions for mean square sense (mss) and\nalmost sure (a.s.) convergence of average consensus when network links fail;\nand, in particular, (3) show that a necessary and sufficient condition for both\nmss and a.s. convergence is for the algebraic connectivity of the mean graph\ndescribing the network topology to be strictly positive. With these results, we\nformulate topology design, subject to random link failures and to a\ncommunication cost constraint, as a constrained convex optimization problem to\nwhich we apply semidefinite programming techniques. We show by an extensive\nnumerical study that the optimal design improves significantly the convergence\nspeed of the consensus algorithm and can achieve the asymptotic performance of\na non-random network at a fraction of the communication cost.\n","versions":[{"version":"v1","created":"Fri, 6 Apr 2007 21:58:52 GMT"}],"update_date":"2009-11-13","authors_parsed":[["Kar","Soummya",""],["Moura","Jose M. F.",""]]}
{"id":"0704.0985","submitter":"Mohd Abubakr","authors":"Mohd Abubakr, R.M.Vinay","title":"Architecture for Pseudo Acausal Evolvable Embedded Systems","comments":"4 pages, 2 figures. Submitted to SASO 2007","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  Advances in semiconductor technology are contributing to the increasing\ncomplexity in the design of embedded systems. Architectures with novel\ntechniques such as evolvable nature and autonomous behavior have engrossed lot\nof attention. This paper demonstrates conceptually evolvable embedded systems\ncan be characterized basing on acausal nature. It is noted that in acausal\nsystems, future input needs to be known, here we make a mechanism such that the\nsystem predicts the future inputs and exhibits pseudo acausal nature. An\nembedded system that uses theoretical framework of acausality is proposed. Our\nmethod aims at a novel architecture that features the hardware evolability and\nautonomous behavior alongside pseudo acausality. Various aspects of this\narchitecture are discussed in detail along with the limitations.\n","versions":[{"version":"v1","created":"Sat, 7 Apr 2007 13:40:49 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Abubakr","Mohd",""],["Vinay","R. M.",""]]}
{"id":"0704.1020","submitter":"Gyorgy Ottucsak","authors":"Andras Gyorgy, Tamas Linder, Gabor Lugosi, Gyorgy Ottucsak","title":"The on-line shortest path problem under partial monitoring","comments":"35 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SC","license":null,"abstract":"  The on-line shortest path problem is considered under various models of\npartial monitoring. Given a weighted directed acyclic graph whose edge weights\ncan change in an arbitrary (adversarial) way, a decision maker has to choose in\neach round of a game a path between two distinguished vertices such that the\nloss of the chosen path (defined as the sum of the weights of its composing\nedges) be as small as possible. In a setting generalizing the multi-armed\nbandit problem, after choosing a path, the decision maker learns only the\nweights of those edges that belong to the chosen path. For this problem, an\nalgorithm is given whose average cumulative loss in n rounds exceeds that of\nthe best path, matched off-line to the entire sequence of the edge weights, by\na quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on\nthe number of edges of the graph. The algorithm can be implemented with linear\ncomplexity in the number of rounds n and in the number of edges. An extension\nto the so-called label efficient setting is also given, in which the decision\nmaker is informed about the weights of the edges corresponding to the chosen\npath at a total of m << n time instances. Another extension is shown where the\ndecision maker competes against a time-varying path, a generalization of the\nproblem of tracking the best expert. A version of the multi-armed bandit\nsetting for shortest path is also discussed where the decision maker learns\nonly the total weight of the chosen path but not the weights of the individual\nedges on the path. Applications to routing in packet switched networks along\nwith simulation results are also presented.\n","versions":[{"version":"v1","created":"Sun, 8 Apr 2007 10:15:54 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Gyorgy","Andras",""],["Linder","Tamas",""],["Lugosi","Gabor",""],["Ottucsak","Gyorgy",""]]}
{"id":"0704.1028","submitter":"Jianlin Cheng","authors":"Jianlin Cheng","title":"A neural network approach to ordinal regression","comments":"8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.NE","license":null,"abstract":"  Ordinal regression is an important type of learning, which has properties of\nboth classification and regression. Here we describe a simple and effective\napproach to adapt a traditional neural network to learn ordinal categories. Our\napproach is a generalization of the perceptron method for ordinal regression.\nOn several benchmark datasets, our method (NNRank) outperforms a neural network\nclassification method. Compared with the ordinal regression methods using\nGaussian processes and support vector machines, NNRank achieves comparable\nperformance. Moreover, NNRank has the advantages of traditional neural\nnetworks: learning in both online and batch modes, handling very large training\ndatasets, and making rapid predictions. These features make NNRank a useful and\ncomplementary tool for large-scale data processing tasks such as information\nretrieval, web page ranking, collaborative filtering, and protein ranking in\nBioinformatics.\n","versions":[{"version":"v1","created":"Sun, 8 Apr 2007 17:36:00 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Cheng","Jianlin",""]]}
{"id":"0704.1158","submitter":"Bernardo Huberman","authors":"Fang Wu and Bernardo A. Huberman","title":"Novelty and Collective Attention","comments":null,"journal-ref":null,"doi":"10.1073/pnas.0704916104","report-no":null,"categories":"cs.CY cs.IR physics.soc-ph","license":null,"abstract":"  The subject of collective attention is central to an information age where\nmillions of people are inundated with daily messages. It is thus of interest to\nunderstand how attention to novel items propagates and eventually fades among\nlarge populations. We have analyzed the dynamics of collective attention among\none million users of an interactive website -- \\texttt{digg.com} -- devoted to\nthousands of novel news stories. The observations can be described by a\ndynamical model characterized by a single novelty factor. Our measurements\nindicate that novelty within groups decays with a stretched-exponential law,\nsuggesting the existence of a natural time scale over which attention fades.\n","versions":[{"version":"v1","created":"Mon, 9 Apr 2007 22:02:29 GMT"}],"update_date":"2009-11-13","authors_parsed":[["Wu","Fang",""],["Huberman","Bernardo A.",""]]}
{"id":"0704.1274","submitter":"Dev Rajnarayan","authors":"David H. Wolpert and Dev G. Rajnarayan","title":"Parametric Learning and Monte Carlo Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":null,"abstract":"  This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.\n","versions":[{"version":"v1","created":"Tue, 10 Apr 2007 17:01:07 GMT"}],"update_date":"2011-11-09","authors_parsed":[["Wolpert","David H.",""],["Rajnarayan","Dev G.",""]]}
{"id":"0704.1394","submitter":"Tarik Had\\v{z}i\\'c","authors":"Tarik Hadzic, Rune Moller Jensen, Henrik Reif Andersen","title":"Calculating Valid Domains for BDD-Based Interactive Configuration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  In these notes we formally describe the functionality of Calculating Valid\nDomains from the BDD representing the solution space of valid configurations.\nThe formalization is largely based on the CLab configuration framework.\n","versions":[{"version":"v1","created":"Wed, 11 Apr 2007 10:59:56 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Hadzic","Tarik",""],["Jensen","Rune Moller",""],["Andersen","Henrik Reif",""]]}
{"id":"0704.1409","submitter":"Yao Hengshuai","authors":"Yao HengShuai","title":"Preconditioned Temporal Difference Learning","comments":"This paper has been withdrawn by the author. Look at the ICML version\n  instead: http://icml2008.cs.helsinki.fi/papers/111.pdf","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":null,"abstract":"  This paper has been withdrawn by the author. This draft is withdrawn for its\npoor quality in english, unfortunately produced by the author when he was just\nstarting his science route. Look at the ICML version instead:\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\n","versions":[{"version":"v1","created":"Wed, 11 Apr 2007 13:17:01 GMT"},{"version":"v2","created":"Thu, 12 Apr 2007 03:33:26 GMT"},{"version":"v3","created":"Fri, 8 Jun 2012 14:08:19 GMT"}],"update_date":"2012-06-11","authors_parsed":[["HengShuai","Yao",""]]}
{"id":"0704.1675","submitter":"Kristina Lerman","authors":"Anon Plangprasopchok and Kristina Lerman","title":"Exploiting Social Annotation for Automatic Resource Discovery","comments":"6 pages, submitted to AAAI07 workshop on Information Integration on\n  the Web","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CY cs.DL","license":null,"abstract":"  Information integration applications, such as mediators or mashups, that\nrequire access to information resources currently rely on users manually\ndiscovering and integrating them in the application. Manual resource discovery\nis a slow process, requiring the user to sift through results obtained via\nkeyword-based search. Although search methods have advanced to include evidence\nfrom document contents, its metadata and the contents and link structure of the\nreferring pages, they still do not adequately cover information sources --\noften called ``the hidden Web''-- that dynamically generate documents in\nresponse to a query. The recently popular social bookmarking sites, which allow\nusers to annotate and share metadata about various information sources, provide\nrich evidence for resource discovery. In this paper, we describe a\nprobabilistic model of the user annotation process in a social bookmarking\nsystem del.icio.us. We then use the model to automatically find resources\nrelevant to a particular information domain. Our experimental results on data\nobtained from \\emph{del.icio.us} show this approach as a promising method for\nhelping automate the resource discovery task.\n","versions":[{"version":"v1","created":"Thu, 12 Apr 2007 23:24:19 GMT"}],"update_date":"2016-09-08","authors_parsed":[["Plangprasopchok","Anon",""],["Lerman","Kristina",""]]}
{"id":"0704.1676","submitter":"Kristina Lerman","authors":"Kristina Lerman, Anon Plangprasopchok and Chio Wong","title":"Personalizing Image Search Results on Flickr","comments":"12 pages, submitted to AAAI07 workshop on Intelligent Information\n  Personalization","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.CY cs.DL cs.HC","license":null,"abstract":"  The social media site Flickr allows users to upload their photos, annotate\nthem with tags, submit them to groups, and also to form social networks by\nadding other users as contacts. Flickr offers multiple ways of browsing or\nsearching it. One option is tag search, which returns all images tagged with a\nspecific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an\ninsect or a car, tag search results will include many images that are not\nrelevant to the sense the user had in mind when executing the query. We claim\nthat users express their photography interests through the metadata they add in\nthe form of contacts and image annotations. We show how to exploit this\nmetadata to personalize search results for the user, thereby improving search\nperformance. First, we show that we can significantly improve search precision\nby filtering tag search results by user's contacts or a larger social network\nthat includes those contact's contacts. Secondly, we describe a probabilistic\nmodel that takes advantage of tag information to discover latent topics\ncontained in the search results. The users' interests can similarly be\ndescribed by the tags they used for annotating their images. The latent topics\nfound by the model are then used to personalize search results by finding\nimages on topics that are of interest to the user.\n","versions":[{"version":"v1","created":"Thu, 12 Apr 2007 23:31:04 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Lerman","Kristina",""],["Plangprasopchok","Anon",""],["Wong","Chio",""]]}
{"id":"0704.1783","submitter":"Francesco Santini","authors":"Stefano Bistarelli, Ugo Montanari, Francesca Rossi, Francesco Santini","title":"Unicast and Multicast Qos Routing with Soft Constraint Logic Programming","comments":"45 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.AI cs.NI","license":null,"abstract":"  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n","versions":[{"version":"v1","created":"Fri, 13 Apr 2007 15:53:44 GMT"},{"version":"v2","created":"Sun, 29 Apr 2007 15:40:10 GMT"},{"version":"v3","created":"Mon, 21 Apr 2008 17:25:06 GMT"}],"update_date":"2009-09-29","authors_parsed":[["Bistarelli","Stefano",""],["Montanari","Ugo",""],["Rossi","Francesca",""],["Santini","Francesco",""]]}
{"id":"0704.2010","submitter":"Juliana Bernardes","authors":"Juliana S Bernardes, Alberto Davila, Vitor Santos Costa, Gerson\n  Zaverucha","title":"A study of structural properties on profiles HMMs","comments":"6 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivation: Profile hidden Markov Models (pHMMs) are a popular and very\nuseful tool in the detection of the remote homologue protein families.\nUnfortunately, their performance is not always satisfactory when proteins are\nin the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm\nand tool that tries to improve pHMM performance by using structural information\nwhile training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs.\nEach pHMM is constructed by weighting each residue in an aligned protein\naccording to a specific structural property of the residue. Properties used\nwere primary, secondary and tertiary structures, accessibility and packing.\nHMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP\ndatabase to perform our experiments. Throughout, we apply leave-one-family-out\ncross-validation over protein superfamilies. First, we used the MAMMOTH-mult\nstructural aligner to align the training set proteins. Then, we performed two\nsets of experiments. In a first experiment, we compared structure weighted\nmodels against standard pHMMs and against each other. In a second experiment,\nwe compared the voting model against individual pHMMs. We compare method\nperformance through ROC curves and through Precision/Recall curves, and assess\nsignificance through the paired two tailed t-test. Our results show significant\nperformance improvements of all structurally weighted models over default\nHMMER, and a significant improvement in sensitivity of the combined models over\nboth the original model and the structurally weighted models.\n","versions":[{"version":"v1","created":"Mon, 16 Apr 2007 13:10:35 GMT"},{"version":"v2","created":"Thu, 11 Dec 2008 18:47:26 GMT"}],"update_date":"2008-12-11","authors_parsed":[["Bernardes","Juliana S",""],["Davila","Alberto",""],["Costa","Vitor Santos",""],["Zaverucha","Gerson",""]]}
{"id":"0704.2083","submitter":"Hassan Satori","authors":"H. Satori, M. Harti and N. Chenfour","title":"Introduction to Arabic Speech Recognition Using CMUSphinx System","comments":"4 pages, 3 figures and 2 tables, was in Information and Communication\n  Technologies International Symposium proceeding ICTIS07 Fes (2007)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":null,"abstract":"  In this paper Arabic was investigated from the speech recognition problem\npoint of view. We propose a novel approach to build an Arabic Automated Speech\nRecognition System (ASR). This system is based on the open source CMU Sphinx-4,\nfrom the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;\nspeaker-independent, continuous speech recognition system based on discrete\nHidden Markov Models (HMMs). We build a model using utilities from the\nOpenSource CMU Sphinx. We will demonstrate the possible adaptability of this\nsystem to Arabic voice recognition.\n","versions":[{"version":"v1","created":"Tue, 17 Apr 2007 01:04:01 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Satori","H.",""],["Harti","M.",""],["Chenfour","N.",""]]}
{"id":"0704.2092","submitter":"Jinsong Tan","authors":"Jinsong Tan","title":"A Note on the Inapproximability of Correlation Clustering","comments":null,"journal-ref":"Information Processing Letters, 108: 331-335, 2008","doi":null,"report-no":null,"categories":"cs.LG cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider inapproximability of the correlation clustering problem defined\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\nvertices into clusters so that the number of pairs correctly (resp.\nincorrectly) classified with respect to the labels is maximized (resp.\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\nrespectively, and have been studied on complete graphs, where every edge is\nlabeled, and general graphs, where some edge might not have been labeled.\nNatural edge-weighted versions of both problems have been studied as well. Let\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$\nessentially belongs to the same hardness class in the following sense: if there\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\n$\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S',\nS'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda\n+ \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high\nprobability. A similar statement also holds for $S-MinDisagree. This result\nimplies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree\nwithin a factor of $80/79-\\epsilon$, improving upon a previous known factor of\n$116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}.\n","versions":[{"version":"v1","created":"Tue, 17 Apr 2007 03:52:41 GMT"},{"version":"v2","created":"Mon, 23 Mar 2009 03:22:02 GMT"}],"update_date":"2009-03-23","authors_parsed":[["Tan","Jinsong",""]]}
{"id":"0704.2201","submitter":"Hassan Satori","authors":"H. Satori, M. Harti and N. Chenfour","title":"Arabic Speech Recognition System using CMU-Sphinx4","comments":"5 pages, 3 figures and 2 tables, in French","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":null,"abstract":"  In this paper we present the creation of an Arabic version of Automated\nSpeech Recognition System (ASR). This system is based on the open source\nSphinx-4, from the Carnegie Mellon University. Which is a speech recognition\nsystem based on discrete hidden Markov models (HMMs). We investigate the\nchanges that must be made to the model to adapt Arabic voice recognition.\n  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,\nCMUSphinx-4, Artificial intelligence.\n","versions":[{"version":"v1","created":"Tue, 17 Apr 2007 17:04:26 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Satori","H.",""],["Harti","M.",""],["Chenfour","N.",""]]}
{"id":"0704.2644","submitter":"Maxim Raginsky","authors":"Maxim Raginsky","title":"Joint universal lossy coding and identification of stationary mixing\n  sources","comments":"5 pages, 1 eps figure; to appear in Proc. ISIT 2007","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.LG math.IT","license":null,"abstract":"  The problem of joint universal source coding and modeling, treated in the\ncontext of lossless codes by Rissanen, was recently generalized to fixed-rate\nlossy coding of finitely parametrized continuous-alphabet i.i.d. sources. We\nextend these results to variable-rate lossy block coding of stationary ergodic\nsources and show that, for bounded metric distortion measures, any finitely\nparametrized family of stationary sources satisfying suitable mixing,\nsmoothness and Vapnik-Chervonenkis learnability conditions admits universal\nschemes for joint lossy source coding and identification. We also give several\nexplicit examples of parametric sources satisfying the regularity conditions.\n","versions":[{"version":"v1","created":"Fri, 20 Apr 2007 01:25:22 GMT"}],"update_date":"2007-07-13","authors_parsed":[["Raginsky","Maxim",""]]}
{"id":"0704.2668","submitter":"Alex Smola J","authors":"Le Song, Alex Smola, Arthur Gretton, Karsten Borgwardt, Justin Bedo","title":"Supervised Feature Selection via Dependence Estimation","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":null,"abstract":"  We introduce a framework for filtering features that employs the\nHilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence\nbetween the features and the labels. The key idea is that good features should\nmaximise such dependence. Feature selection for various supervised learning\nproblems (including classification and regression) is unified under this\nframework, and the solutions can be approximated using a backward-elimination\nalgorithm. We demonstrate the usefulness of our method on both artificial and\nreal world datasets.\n","versions":[{"version":"v1","created":"Fri, 20 Apr 2007 08:26:29 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Song","Le",""],["Smola","Alex",""],["Gretton","Arthur",""],["Borgwardt","Karsten",""],["Bedo","Justin",""]]}
{"id":"0704.2902","submitter":"Stefan Pohl","authors":"Stefan Pohl, Filip Radlinski and Thorsten Joachims","title":"Recommending Related Papers Based on Digital Library Access Records","comments":"2 pages, 3 postscript figures, to appear in proceedings of JCDL'07,\n  additional and more detailed results can be found in arXiv:0704.2963v1","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.IR","license":null,"abstract":"  An important goal for digital libraries is to enable researchers to more\neasily explore related work. While citation data is often used as an indicator\nof relatedness, in this paper we demonstrate that digital access records (e.g.\nhttp-server logs) can be used as indicators as well. In particular, we show\nthat measures based on co-access provide better coverage than co-citation, that\nthey are available much sooner, and that they are more accurate for recent\npapers.\n","versions":[{"version":"v1","created":"Mon, 23 Apr 2007 16:51:40 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Pohl","Stefan",""],["Radlinski","Filip",""],["Joachims","Thorsten",""]]}
{"id":"0704.2963","submitter":"Stefan Pohl","authors":"Stefan Pohl","title":"Using Access Data for Paper Recommendations on ArXiv.org","comments":"73 pages, 31 figures, Master's Thesis","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.IR","license":null,"abstract":"  This thesis investigates in the use of access log data as a source of\ninformation for identifying related scientific papers. This is done for\narXiv.org, the authority for publication of e-prints in several fields of\nphysics.\n  Compared to citation information, access logs have the advantage of being\nimmediately available, without manual or automatic extraction of the citation\ngraph. Because of that, a main focus is on the question, how far user behavior\ncan serve as a replacement for explicit meta-data, which potentially might be\nexpensive or completely unavailable. Therefore, we compare access, content, and\ncitation-based measures of relatedness on different recommendation tasks. As a\nfinal result, an online recommendation system has been built that can help\nscientists to find further relevant literature, without having to search for\nthem actively.\n","versions":[{"version":"v1","created":"Mon, 23 Apr 2007 15:52:47 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Pohl","Stefan",""]]}
{"id":"0704.3157","submitter":"Giorgio Terracina","authors":"Giorgio Terracina, Nicola Leone, Vincenzino Lio, Claudio Panetta","title":"Experimenting with recursive queries in database and logic programming\n  systems","comments":"To appear in Theory and Practice of Logic Programming (TPLP)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DB","license":null,"abstract":"  This paper considers the problem of reasoning on massive amounts of (possibly\ndistributed) data. Presently, existing proposals show some limitations: {\\em\n(i)} the quantity of data that can be handled contemporarily is limited, due to\nthe fact that reasoning is generally carried out in main-memory; {\\em (ii)} the\ninteraction with external (and independent) DBMSs is not trivial and, in\nseveral cases, not allowed at all; {\\em (iii)} the efficiency of present\nimplementations is still not sufficient for their utilization in complex\nreasoning tasks involving massive amounts of data. This paper provides a\ncontribution in this setting; it presents a new system, called DLV$^{DB}$,\nwhich aims to solve these problems. Moreover, the paper reports the results of\na thorough experimental analysis we have carried out for comparing our system\nwith several state-of-the-art systems (both logic and databases) on some\nclassical deductive problems; the other tested systems are: LDL++, XSB, Smodels\nand three top-level commercial DBMSs. DLV$^{DB}$ significantly outperforms even\nthe commercial Database Systems on recursive queries. To appear in Theory and\nPractice of Logic Programming (TPLP)\n","versions":[{"version":"v1","created":"Tue, 24 Apr 2007 10:58:40 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Terracina","Giorgio",""],["Leone","Nicola",""],["Lio","Vincenzino",""],["Panetta","Claudio",""]]}
{"id":"0704.3316","submitter":"Ciro Cattuto","authors":"Ciro Cattuto, Andrea Baldassarri, Vito D. P. Servedio, Vittorio Loreto","title":"Vocabulary growth in collaborative tagging systems","comments":"6 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cond-mat.stat-mech cs.CY physics.data-an","license":null,"abstract":"  We analyze a large-scale snapshot of del.icio.us and investigate how the\nnumber of different tags in the system grows as a function of a suitably\ndefined notion of time. We study the temporal evolution of the global\nvocabulary size, i.e. the number of distinct tags in the entire system, as well\nas the evolution of local vocabularies, that is the growth of the number of\ndistinct tags used in the context of a given resource or user. In both cases,\nwe find power-law behaviors with exponents smaller than one. Surprisingly, the\nobserved growth behaviors are remarkably regular throughout the entire history\nof the system and across very different resources being bookmarked. Similar\nsub-linear laws of growth have been observed in written text, and this\nqualitative universality calls for an explanation and points in the direction\nof non-trivial cognitive processes in the complex interaction patterns\ncharacterizing collaborative tagging.\n","versions":[{"version":"v1","created":"Wed, 25 Apr 2007 07:47:40 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Cattuto","Ciro",""],["Baldassarri","Andrea",""],["Servedio","Vito D. P.",""],["Loreto","Vittorio",""]]}
{"id":"0704.3359","submitter":"Alex Smola J","authors":"Quoc Le and Alexander Smola","title":"Direct Optimization of Ranking Measures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI","license":null,"abstract":"  Web page ranking and collaborative filtering require the optimization of\nsophisticated performance measures. Current Support Vector approaches are\nunable to optimize them directly and focus on pairwise comparisons instead. We\npresent a new approach which allows direct optimization of the relevant loss\nfunctions. This is achieved via structured estimation in Hilbert spaces. It is\nmost related to Max-Margin-Markov networks optimization of multivariate\nperformance measures. Key to our approach is that during training the ranking\nproblem can be viewed as a linear assignment problem, which can be solved by\nthe Hungarian Marriage algorithm. At test time, a sort operation is sufficient,\nas our algorithm assigns a relevance score to every (document, query) pair.\nExperiments show that the our algorithm is fast and that it works very well.\n","versions":[{"version":"v1","created":"Wed, 25 Apr 2007 12:36:55 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Le","Quoc",""],["Smola","Alexander",""]]}
{"id":"0704.3395","submitter":"Marko A. Rodriguez","authors":"Marko A. Rodriguez","title":"General-Purpose Computing on a Semantic Network Substrate","comments":null,"journal-ref":"Emergent Web Intelligence: Advanced Semantic Technologies,\n  Advanced Information and Knowledge Processing series, Springer-Verlag, pages\n  57-104, ISBN:978-1-84996-076-2, June 2010","doi":null,"report-no":"LA-UR-07-2885","categories":"cs.AI cs.PL","license":"http://creativecommons.org/licenses/publicdomain/","abstract":"  This article presents a model of general-purpose computing on a semantic\nnetwork substrate. The concepts presented are applicable to any semantic\nnetwork representation. However, due to the standards and technological\ninfrastructure devoted to the Semantic Web effort, this article is presented\nfrom this point of view. In the proposed model of computing, the application\nprogramming interface, the run-time program, and the state of the computing\nvirtual machine are all represented in the Resource Description Framework\n(RDF). The implementation of the concepts presented provides a practical\ncomputing paradigm that leverages the highly-distributed and standardized\nrepresentational-layer of the Semantic Web.\n","versions":[{"version":"v1","created":"Wed, 25 Apr 2007 15:37:52 GMT"},{"version":"v2","created":"Thu, 4 Oct 2007 20:08:21 GMT"},{"version":"v3","created":"Sun, 7 Oct 2007 21:44:01 GMT"},{"version":"v4","created":"Sun, 6 Jun 2010 05:29:22 GMT"}],"update_date":"2010-06-08","authors_parsed":[["Rodriguez","Marko A.",""]]}
{"id":"0704.3433","submitter":"Tshilidzi Marwala","authors":"Tshilidzi Marwala and Bodie Crossingham","title":"Bayesian approach to rough set","comments":"20 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper proposes an approach to training rough set models using Bayesian\nframework trained using Markov Chain Monte Carlo (MCMC) method. The prior\nprobabilities are constructed from the prior knowledge that good rough set\nmodels have fewer rules. Markov Chain Monte Carlo sampling is conducted through\nsampling in the rough set granule space and Metropolis algorithm is used as an\nacceptance criteria. The proposed method is tested to estimate the risk of HIV\ngiven demographic data. The results obtained shows that the proposed approach\nis able to achieve an average accuracy of 58% with the accuracy varying up to\n66%. In addition the Bayesian rough set give the probabilities of the estimated\nHIV status as well as the linguistic rules describing how the demographic\nparameters drive the risk of HIV.\n","versions":[{"version":"v1","created":"Wed, 25 Apr 2007 19:50:59 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Marwala","Tshilidzi",""],["Crossingham","Bodie",""]]}
{"id":"0704.3453","submitter":"Tshilidzi Marwala","authors":"S. Mohamed, D. Rubin, and T. Marwala","title":"An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors","comments":"9 pages, 5 tables, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI q-bio.QM","license":null,"abstract":"  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n","versions":[{"version":"v1","created":"Wed, 25 Apr 2007 21:23:31 GMT"}],"update_date":"2007-06-25","authors_parsed":[["Mohamed","S.",""],["Rubin","D.",""],["Marwala","T.",""]]}
{"id":"0704.3515","submitter":"Jegor Uglov Mr","authors":"J. Uglov, V. Schetinin, C. Maple","title":"Comparing Robustness of Pairwise and Multiclass Neural-Network Systems\n  for Face Recognition","comments":null,"journal-ref":null,"doi":"10.1155/2008/468693","report-no":null,"categories":"cs.AI","license":null,"abstract":"  Noise, corruptions and variations in face images can seriously hurt the\nperformance of face recognition systems. To make such systems robust,\nmulticlass neuralnetwork classifiers capable of learning from noisy data have\nbeen suggested. However on large face data sets such systems cannot provide the\nrobustness at a high level. In this paper we explore a pairwise neural-network\nsystem as an alternative approach to improving the robustness of face\nrecognition. In our experiments this approach is shown to outperform the\nmulticlass neural-network system in terms of the predictive accuracy on the\nface images corrupted by noise.\n","versions":[{"version":"v1","created":"Thu, 26 Apr 2007 11:29:19 GMT"}],"update_date":"2016-02-17","authors_parsed":[["Uglov","J.",""],["Schetinin","V.",""],["Maple","C.",""]]}
{"id":"0704.3635","submitter":"Fulufhelo Vincent Nelwamondo","authors":"Fulufhelo Vincent Nelwamondo and Tshilidzi Marwala","title":"Rough Sets Computations to Impute Missing Data","comments":"19 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.IR","license":null,"abstract":"  Many techniques for handling missing data have been proposed in the\nliterature. Most of these techniques are overly complex. This paper explores an\nimputation technique based on rough set computations. In this paper,\ncharacteristic relations are introduced to describe incompletely specified\ndecision tables.It is shown that the basic rough set idea of lower and upper\napproximations for incompletely specified decision tables may be defined in a\nvariety of different ways. Empirical results obtained using real data are given\nand they provide a valuable and promising insight to the problem of missing\ndata. Missing data were predicted with an accuracy of up to 99%.\n","versions":[{"version":"v1","created":"Thu, 26 Apr 2007 22:22:45 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Nelwamondo","Fulufhelo Vincent",""],["Marwala","Tshilidzi",""]]}
{"id":"0704.3886","submitter":"W Saba","authors":"Walid S. Saba","title":"A Note on Ontology and Ordinary Language","comments":"19 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL","license":null,"abstract":"  We argue for a compositional semantics grounded in a strongly typed ontology\nthat reflects our commonsense view of the world and the way we talk about it.\nAssuming such a structure we show that the semantics of various natural\nlanguage phenomena may become nearly trivial.\n","versions":[{"version":"v1","created":"Mon, 30 Apr 2007 17:55:39 GMT"},{"version":"v2","created":"Tue, 1 May 2007 13:43:32 GMT"},{"version":"v3","created":"Wed, 2 May 2007 18:13:22 GMT"},{"version":"v4","created":"Thu, 3 May 2007 08:34:47 GMT"},{"version":"v5","created":"Fri, 4 May 2007 17:49:03 GMT"},{"version":"v6","created":"Mon, 7 May 2007 16:04:50 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Saba","Walid S.",""]]}
{"id":"0704.3905","submitter":"Marc Schoenauer","authors":"Christian Gagn\\'e (INFORMATIQUE WGZ INC.), Mich\\`ele Sebag (INRIA\n  Futurs), Marc Schoenauer (INRIA Futurs), Marco Tomassini (ISI)","title":"Ensemble Learning for Free with Evolutionary Algorithms ?","comments":null,"journal-ref":"Dans GECCO (2007)","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Evolutionary Learning proceeds by evolving a population of classifiers, from\nwhich it generally returns (with some notable exceptions) the single\nbest-of-run classifier as final result. In the meanwhile, Ensemble Learning,\none of the most efficient approaches in supervised Machine Learning for the\nlast decade, proceeds by building a population of diverse classifiers. Ensemble\nLearning with Evolutionary Computation thus receives increasing attention. The\nEvolutionary Ensemble Learning (EEL) approach presented in this paper features\ntwo contributions. First, a new fitness function, inspired by co-evolution and\nenforcing the classifier diversity, is presented. Further, a new selection\ncriterion based on the classification margin is proposed. This criterion is\nused to extract the classifier ensemble from the final population only\n(Off-line) or incrementally along evolution (On-line). Experiments on a set of\nbenchmark problems show that Off-line outperforms single-hypothesis\nevolutionary learning and state-of-art Boosting and generates smaller\nclassifier ensembles.\n","versions":[{"version":"v1","created":"Mon, 30 Apr 2007 09:29:22 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Gagn\u00e9","Christian","","INFORMATIQUE WGZ INC."],["Sebag","Mich\u00e8le","","INRIA\n  Futurs"],["Schoenauer","Marc","","INRIA Futurs"],["Tomassini","Marco","","ISI"]]}
{"id":"0705.0025","submitter":"Andreas Martin Lisewski","authors":"Andreas Martin Lisewski","title":"Can the Internet cope with stress?","comments":"4 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.AI","license":null,"abstract":"  When will the Internet become aware of itself? In this note the problem is\napproached by asking an alternative question: Can the Internet cope with\nstress? By extrapolating the psychological difference between coping and\ndefense mechanisms a distributed software experiment is outlined which could\nreject the hypothesis that the Internet is not a conscious entity.\n","versions":[{"version":"v1","created":"Tue, 1 May 2007 15:44:17 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Lisewski","Andreas Martin",""]]}
{"id":"0705.0197","submitter":"Tshilidzi Marwala","authors":"Tshilidzi Marwala, Unathi Mahola and Snehashish Chakraverty","title":"Fault Classification in Cylinders Using Multilayer Perceptrons, Support\n  Vector Machines and Guassian Mixture Models","comments":"10 pages, 2 figures, 4 tables","journal-ref":"Computer Assisted Mechanics and Engineering Sciences, Vol. 14, No.\n  2, 2007.","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Gaussian mixture models (GMM) and support vector machines (SVM) are\nintroduced to classify faults in a population of cylindrical shells. The\nproposed procedures are tested on a population of 20 cylindrical shells and\ntheir performance is compared to the procedure, which uses multi-layer\nperceptrons (MLP). The modal properties extracted from vibration data are used\nto train the GMM, SVM and MLP. It is observed that the GMM produces 98%, SVM\nproduces 94% classification accuracy while the MLP produces 88% classification\nrates.\n","versions":[{"version":"v1","created":"Wed, 2 May 2007 03:13:28 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Marwala","Tshilidzi",""],["Mahola","Unathi",""],["Chakraverty","Snehashish",""]]}
{"id":"0705.0199","submitter":"Erik Berglund","authors":"Erik Berglund, Joaquin Sitte","title":"The Parameter-Less Self-Organizing Map algorithm","comments":"29 pages, 27 figures. Based on publication in IEEE Trans. on Neural\n  Networks","journal-ref":"IEEE Transactions on Neural Networks, 2006 v.17, n.2, pp.305-316","doi":null,"report-no":null,"categories":"cs.NE cs.AI cs.CV","license":null,"abstract":"  The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network\nalgorithm based on the Self-Organizing Map (SOM). It eliminates the need for a\nlearning rate and annealing schemes for learning rate and neighbourhood size.\nWe discuss the relative performance of the PLSOM and the SOM and demonstrate\nsome tasks in which the SOM fails but the PLSOM performs satisfactory. Finally\nwe discuss some example applications of the PLSOM and present a proof of\nordering under certain limited conditions.\n","versions":[{"version":"v1","created":"Wed, 2 May 2007 04:04:51 GMT"},{"version":"v2","created":"Tue, 8 May 2007 01:06:10 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Berglund","Erik",""],["Sitte","Joaquin",""]]}
{"id":"0705.0588","submitter":"Edgar Graaf de","authors":"Edgar H. de Graaf, Joost N. Kok, Walter A. Kosters","title":"Clustering Co-occurrence of Maximal Frequent Patterns in Streams","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DS","license":null,"abstract":"  One way of getting a better view of data is using frequent patterns. In this\npaper frequent patterns are subsets that occur a minimal number of times in a\nstream of itemsets. However, the discovery of frequent patterns in streams has\nalways been problematic. Because streams are potentially endless it is in\nprinciple impossible to say if a pattern is often occurring or not. Furthermore\nthe number of patterns can be huge and a good overview of the structure of the\nstream is lost quickly. The proposed approach will use clustering to facilitate\nthe analysis of the structure of the stream.\n  A clustering on the co-occurrence of patterns will give the user an improved\nview on the structure of the stream. Some patterns might occur so much together\nthat they should form a combined pattern. In this way the patterns in the\nclustering will be the largest frequent patterns: maximal frequent patterns.\n  Our approach to decide if patterns occur often together will be based on a\nmethod of clustering when only the distance between pairs is known. The number\nof maximal frequent patterns is much smaller and combined with clustering\nmethods these patterns provide a good view on the structure of the stream.\n","versions":[{"version":"v1","created":"Fri, 4 May 2007 10:36:53 GMT"}],"update_date":"2007-05-23","authors_parsed":[["de Graaf","Edgar H.",""],["Kok","Joost N.",""],["Kosters","Walter A.",""]]}
{"id":"0705.0593","submitter":"Edgar Graaf de","authors":"Edgar H. de Graaf, Joost N. Kok, Walter A. Kosters","title":"Clustering with Lattices in the Analysis of Graph Patterns","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DS","license":null,"abstract":"  Mining frequent subgraphs is an area of research where we have a given set of\ngraphs (each graph can be seen as a transaction), and we search for (connected)\nsubgraphs contained in many of these graphs. In this work we will discuss\ntechniques used in our framework Lattice2SAR for mining and analysing frequent\nsubgraph data and their corresponding lattice information. Lattice information\nis provided by the graph mining algorithm gSpan; it contains all\nsupergraph-subgraph relations of the frequent subgraph patterns -- and their\nsupports.\n  Lattice2SAR is in particular used in the analysis of frequent graph patterns\nwhere the graphs are molecules and the frequent subgraphs are fragments. In the\nanalysis of fragments one is interested in the molecules where patterns occur.\nThis data can be very extensive and in this paper we focus on a technique of\nmaking it better available by using the lattice information in our clustering.\nNow we can reduce the number of times the highly compressed occurrence data\nneeds to be accessed by the user. The user does not have to browse all the\noccurrence data in search of patterns occurring in the same molecules. Instead\none can directly see which frequent subgraphs are of interest.\n","versions":[{"version":"v1","created":"Fri, 4 May 2007 10:52:28 GMT"}],"update_date":"2007-05-23","authors_parsed":[["de Graaf","Edgar H.",""],["Kok","Joost N.",""],["Kosters","Walter A.",""]]}
{"id":"0705.0693","submitter":"Tshilidzi Marwala","authors":"Evan Hurwitz and Tshilidzi Marwala","title":"Learning to Bluff","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  The act of bluffing confounds game designers to this day. The very nature of\nbluffing is even open for debate, adding further complication to the process of\ncreating intelligent virtual players that can bluff, and hence play,\nrealistically. Through the use of intelligent, learning agents, and carefully\ndesigned agent outlooks, an agent can in fact learn to predict its opponents\nreactions based not only on its own cards, but on the actions of those around\nit. With this wider scope of understanding, an agent can in learn to bluff its\nopponents, with the action representing not an illogical action, as bluffing is\noften viewed, but rather as an act of maximising returns through an effective\nstatistical optimisation. By using a tee dee lambda learning algorithm to\ncontinuously adapt neural network agent intelligence, agents have been shown to\nbe able to learn to bluff without outside prompting, and even to learn to call\neach others bluffs in free, competitive play.\n","versions":[{"version":"v1","created":"Mon, 7 May 2007 19:15:24 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Hurwitz","Evan",""],["Marwala","Tshilidzi",""]]}
{"id":"0705.0734","submitter":"Sanjiang Li","authors":"Sanjiang Li and Mingsheng Ying","title":"Soft constraint abstraction based on semiring homomorphism","comments":"18 pages, 1 figure","journal-ref":"Theoretical Computer Science 403(2-3) 192-201, 2008","doi":"10.1016/j.tcs.2008.03.029","report-no":null,"categories":"cs.AI","license":null,"abstract":"  The semiring-based constraint satisfaction problems (semiring CSPs), proposed\nby Bistarelli, Montanari and Rossi \\cite{BMR97}, is a very general framework of\nsoft constraints. In this paper we propose an abstraction scheme for soft\nconstraints that uses semiring homomorphism. To find optimal solutions of the\nconcrete problem, the idea is, first working in the abstract problem and\nfinding its optimal solutions, then using them to solve the concrete problem.\n  In particular, we show that a mapping preserves optimal solutions if and only\nif it is an order-reflecting semiring homomorphism. Moreover, for a semiring\nhomomorphism $\\alpha$ and a problem $P$ over $S$, if $t$ is optimal in\n$\\alpha(P)$, then there is an optimal solution $\\bar{t}$ of $P$ such that\n$\\bar{t}$ has the same value as $t$ in $\\alpha(P)$.\n","versions":[{"version":"v1","created":"Sat, 5 May 2007 08:47:31 GMT"}],"update_date":"2010-07-01","authors_parsed":[["Li","Sanjiang",""],["Ying","Mingsheng",""]]}
{"id":"0705.0751","submitter":"Pere Constans","authors":"Pere Constans","title":"Approximate textual retrieval","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.DL","license":null,"abstract":"  An approximate textual retrieval algorithm for searching sources with high\nlevels of defects is presented. It considers splitting the words in a query\ninto two overlapping segments and subsequently building composite regular\nexpressions from interlacing subsets of the segments. This procedure reduces\nthe probability of missed occurrences due to source defects, yet diminishes the\nretrieval of irrelevant, non-contextual occurrences.\n","versions":[{"version":"v1","created":"Sat, 5 May 2007 17:27:42 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Constans","Pere",""]]}
{"id":"0705.0760","submitter":"Sujay Sanghavi","authors":"Sujay Sanghavi","title":"Equivalence of LP Relaxation and Max-Product for Weighted Matching in\n  General Graphs","comments":"6 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.AI cs.LG cs.NI math.IT","license":null,"abstract":"  Max-product belief propagation is a local, iterative algorithm to find the\nmode/MAP estimate of a probability distribution. While it has been successfully\nemployed in a wide variety of applications, there are relatively few\ntheoretical guarantees of convergence and correctness for general loopy graphs\nthat may have many short cycles. Of these, even fewer provide exact ``necessary\nand sufficient'' characterizations.\n  In this paper we investigate the problem of using max-product to find the\nmaximum weight matching in an arbitrary graph with edge weights. This is done\nby first constructing a probability distribution whose mode corresponds to the\noptimal matching, and then running max-product. Weighted matching can also be\nposed as an integer program, for which there is an LP relaxation. This\nrelaxation is not always tight. In this paper we show that \\begin{enumerate}\n\\item If the LP relaxation is tight, then max-product always converges, and\nthat too to the correct answer. \\item If the LP relaxation is loose, then\nmax-product does not converge. \\end{enumerate} This provides an exact,\ndata-dependent characterization of max-product performance, and a precise\nconnection to LP relaxation, which is a well-studied optimization technique.\nAlso, since LP relaxation is known to be tight for bipartite graphs, our\nresults generalize other recent results on using max-product to find weighted\nmatchings in bipartite graphs.\n","versions":[{"version":"v1","created":"Sat, 5 May 2007 18:57:47 GMT"}],"update_date":"2007-07-13","authors_parsed":[["Sanghavi","Sujay",""]]}
{"id":"0705.0761","submitter":"Tshilidzi Marwala","authors":"Tshilidzi Marwala and Bodie Crossingham","title":"Bayesian Approach to Neuro-Rough Models","comments":"24 pages, 5 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper proposes a neuro-rough model based on multi-layered perceptron and\nrough set. The neuro-rough model is then tested on modelling the risk of HIV\nfrom demographic data. The model is formulated using Bayesian framework and\ntrained using Monte Carlo method and Metropolis criterion. When the model was\ntested to estimate the risk of HIV infection given the demographic data it was\nfound to give the accuracy of 62%. The proposed model is able to combine the\naccuracy of the Bayesian MLP model and the transparency of Bayesian rough set\nmodel.\n","versions":[{"version":"v1","created":"Sun, 6 May 2007 22:55:58 GMT"},{"version":"v2","created":"Wed, 9 May 2007 04:13:04 GMT"},{"version":"v3","created":"Tue, 28 Aug 2007 09:24:46 GMT"}],"update_date":"2007-08-28","authors_parsed":[["Marwala","Tshilidzi",""],["Crossingham","Bodie",""]]}
{"id":"0705.0969","submitter":"Tshilidzi Marwala","authors":"Ishmael S. Msiza, Fulufhelo V. Nelwamondo and Tshilidzi Marwala","title":"Artificial Neural Networks and Support Vector Machines for Water Demand\n  Time Series Forecasting","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Water plays a pivotal role in many physical processes, and most importantly\nin sustaining human life, animal life and plant life. Water supply entities\ntherefore have the responsibility to supply clean and safe water at the rate\nrequired by the consumer. It is therefore necessary to implement mechanisms and\nsystems that can be employed to predict both short-term and long-term water\ndemands. The increasingly growing field of computational intelligence\ntechniques has been proposed as an efficient tool in the modelling of dynamic\nphenomena. The primary objective of this paper is to compare the efficiency of\ntwo computational intelligence techniques in water demand forecasting. The\ntechniques under comparison are the Artificial Neural Networks (ANNs) and the\nSupport Vector Machines (SVMs). In this study it was observed that the ANNs\nperform better than the SVMs. This performance is measured against the\ngeneralisation ability of the two.\n","versions":[{"version":"v1","created":"Mon, 7 May 2007 19:00:28 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Msiza","Ishmael S.",""],["Nelwamondo","Fulufhelo V.",""],["Marwala","Tshilidzi",""]]}
{"id":"0705.1031","submitter":"Tshilidzi Marwala","authors":"F.V. Nelwamondo and T. Marwala","title":"Fuzzy Artmap and Neural Network Approach to Online Processing of Inputs\n  with Missing Values","comments":"7 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  An ensemble based approach for dealing with missing data, without predicting\nor imputing the missing values is proposed. This technique is suitable for\nonline operations of neural networks and as a result, is used for online\ncondition monitoring. The proposed technique is tested in both classification\nand regression problems. An ensemble of Fuzzy-ARTMAPs is used for\nclassification whereas an ensemble of multi-layer perceptrons is used for the\nregression problem. Results obtained using this ensemble-based technique are\ncompared to those obtained using a combination of auto-associative neural\nnetworks and genetic algorithms and findings show that this method can perform\nup to 9% better in regression problems. Another advantage of the proposed\ntechnique is that it eliminates the need for finding the best estimate of the\ndata, and hence, saves time.\n","versions":[{"version":"v1","created":"Tue, 8 May 2007 05:12:01 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Nelwamondo","F. V.",""],["Marwala","T.",""]]}
{"id":"0705.1110","submitter":"Edgar Graaf de","authors":"Edgar de Graaf Joost Kok Walter Kosters","title":"Mining Patterns with a Balanced Interval","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DB","license":null,"abstract":"  In many applications it will be useful to know those patterns that occur with\na balanced interval, e.g., a certain combination of phone numbers are called\nalmost every Friday or a group of products are sold a lot on Tuesday and\nThursday.\n  In previous work we proposed a new measure of support (the number of\noccurrences of a pattern in a dataset), where we count the number of times a\npattern occurs (nearly) in the middle between two other occurrences. If the\nnumber of non-occurrences between two occurrences of a pattern stays almost the\nsame then we call the pattern balanced.\n  It was noticed that some very frequent patterns obviously also occur with a\nbalanced interval, meaning in every transaction. However more interesting\npatterns might occur, e.g., every three transactions. Here we discuss a\nsolution using standard deviation and average. Furthermore we propose a simpler\napproach for pruning patterns with a balanced interval, making estimating the\npruning threshold more intuitive.\n","versions":[{"version":"v1","created":"Tue, 8 May 2007 15:22:38 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Kosters","Edgar de Graaf Joost Kok Walter",""]]}
{"id":"0705.1161","submitter":"Lillian Lee","authors":"Lillian Lee","title":"IDF revisited: A simple new derivation within the Robertson-Sp\\\"arck\n  Jones probabilistic model","comments":"To appear, Proceedings of SIGIR 2007, poster paper (2 pages)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.CL","license":null,"abstract":"  There have been a number of prior attempts to theoretically justify the\neffectiveness of the inverse document frequency (IDF). Those that take as their\nstarting point Robertson and Sparck Jones's probabilistic model are based on\nstrong or complex assumptions. We show that a more intuitively plausible\nassumption suffices. Moreover, the new assumption, while conceptually very\nsimple, provides a solution to an estimation problem that had been deemed\nintractable by Robertson and Walker (1997).\n","versions":[{"version":"v1","created":"Tue, 8 May 2007 20:08:13 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Lee","Lillian",""]]}
{"id":"0705.1209","submitter":"Tshilidzi Marwala","authors":"E. Habtemariam, T. Marwala and M. Lagazio","title":"Artificial Intelligence for Conflict Management","comments":"20 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Militarised conflict is one of the risks that have a significant impact on\nsociety. Militarised Interstate Dispute (MID) is defined as an outcome of\ninterstate interactions, which result on either peace or conflict. Effective\nprediction of the possibility of conflict between states is an important\ndecision support tool for policy makers. In a previous research, neural\nnetworks (NNs) have been implemented to predict the MID. Support Vector\nMachines (SVMs) have proven to be very good prediction techniques and are\nintroduced for the prediction of MIDs in this study and compared to neural\nnetworks. The results show that SVMs predict MID better than NNs while NNs give\nmore consistent and easy to interpret sensitivity analysis than SVMs.\n","versions":[{"version":"v1","created":"Wed, 9 May 2007 05:53:30 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Habtemariam","E.",""],["Marwala","T.",""],["Lagazio","M.",""]]}
{"id":"0705.1244","submitter":"Marc Schoenauer","authors":"Nicolas Godzik (INRIA Futurs, INRIA Rocquencourt), Marc Schoenauer\n  (INRIA Futurs, INRIA Rocquencourt), Mich\\`ele Sebag (INRIA Futurs, LRI)","title":"Evolving Symbolic Controllers","comments":null,"journal-ref":"Dans 4th European Workshop on Evolutionary Robotics, 2611 (2003)\n  638-650","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  The idea of symbolic controllers tries to bridge the gap between the top-down\nmanual design of the controller architecture, as advocated in Brooks'\nsubsumption architecture, and the bottom-up designer-free approach that is now\nstandard within the Evolutionary Robotics community. The designer provides a\nset of elementary behavior, and evolution is given the goal of assembling them\nto solve complex tasks. Two experiments are presented, demonstrating the\nefficiency and showing the recursiveness of this approach. In particular, the\nsensitivity with respect to the proposed elementary behaviors, and the\nrobustness w.r.t. generalization of the resulting controllers are studied in\ndetail.\n","versions":[{"version":"v1","created":"Wed, 9 May 2007 09:53:31 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Godzik","Nicolas","","INRIA Futurs, INRIA Rocquencourt"],["Schoenauer","Marc","","INRIA Futurs, INRIA Rocquencourt"],["Sebag","Mich\u00e8le","","INRIA Futurs, LRI"]]}
{"id":"0705.1309","submitter":"Marc Schoenauer","authors":"Alexandre Devert (INRIA Futurs), Nicolas Bred\\`eche (INRIA Futurs),\n  Marc Schoenauer (INRIA Futurs)","title":"Robust Multi-Cellular Developmental Design","comments":null,"journal-ref":"Dans Genetic and Evolutionary Computation COnference (2007)","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper introduces a continuous model for Multi-cellular Developmental\nDesign. The cells are fixed on a 2D grid and exchange \"chemicals\" with their\nneighbors during the growth process. The quantity of chemicals that a cell\nproduces, as well as the differentiation value of the cell in the phenotype,\nare controlled by a Neural Network (the genotype) that takes as inputs the\nchemicals produced by the neighboring cells at the previous time step. In the\nproposed model, the number of iterations of the growth process is not\npre-determined, but emerges during evolution: only organisms for which the\ngrowth process stabilizes give a phenotype (the stable state), others are\ndeclared nonviable. The optimization of the controller is done using the NEAT\nalgorithm, that optimizes both the topology and the weights of the Neural\nNetworks. Though each cell only receives local information from its neighbors,\nthe experimental results of the proposed approach on the 'flags' problems (the\nphenotype must match a given 2D pattern) are almost as good as those of a\ndirect regression approach using the same model with global information.\nMoreover, the resulting multi-cellular organisms exhibit almost perfect\nself-healing characteristics.\n","versions":[{"version":"v1","created":"Wed, 9 May 2007 15:33:34 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Devert","Alexandre","","INRIA Futurs"],["Bred\u00e8che","Nicolas","","INRIA Futurs"],["Schoenauer","Marc","","INRIA Futurs"]]}
{"id":"0705.1585","submitter":"Tshilidzi Marwala","authors":"Unathi Mahola, Fulufhelo V. Nelwamondo, Tshilidzi Marwala","title":"HMM Speaker Identification Using Linear and Non-linear Merging\n  Techniques","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":null,"abstract":"  Speaker identification is a powerful, non-invasive and in-expensive biometric\ntechnique. The recognition accuracy, however, deteriorates when noise levels\naffect a specific band of frequency. In this paper, we present a sub-band based\nspeaker identification that intends to improve the live testing performance.\nEach frequency sub-band is processed and classified independently. We also\ncompare the linear and non-linear merging techniques for the sub-bands\nrecognizer. Support vector machines and Gaussian Mixture models are the\nnon-linear merging techniques that are investigated. Results showed that the\nsub-band based method used with linear merging techniques enormously improved\nthe performance of the speaker identification over the performance of wide-band\nrecognizers when tested live. A live testing improvement of 9.78% was achieved\n","versions":[{"version":"v1","created":"Fri, 11 May 2007 04:54:54 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Mahola","Unathi",""],["Nelwamondo","Fulufhelo V.",""],["Marwala","Tshilidzi",""]]}
{"id":"0705.1617","submitter":"Daegene Song","authors":"Daegene Song","title":"Non-Computability of Consciousness","comments":"10 pages, 2 figures, 1 table","journal-ref":"NeuroQuantology 5, 382 (2007).","doi":null,"report-no":null,"categories":"quant-ph astro-ph cs.AI","license":null,"abstract":"  With the great success in simulating many intelligent behaviors using\ncomputing devices, there has been an ongoing debate whether all conscious\nactivities are computational processes. In this paper, the answer to this\nquestion is shown to be no. A certain phenomenon of consciousness is\ndemonstrated to be fully represented as a computational process using a quantum\ncomputer. Based on the computability criterion discussed with Turing machines,\nthe model constructed is shown to necessarily involve a non-computable element.\nThe concept that this is solely a quantum effect and does not work for a\nclassical case is also discussed.\n","versions":[{"version":"v1","created":"Fri, 11 May 2007 10:16:48 GMT"}],"update_date":"2011-11-09","authors_parsed":[["Song","Daegene",""]]}
{"id":"0705.1673","submitter":"Tshilidzi Marwala","authors":"L. Mdlazi, C.J. Stander, P.S. Heyns and T. Marwala","title":"Using artificial intelligence for data reduction in mechanical\n  engineering","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CE cs.AI cs.NE","license":null,"abstract":"  In this paper artificial neural networks and support vector machines are used\nto reduce the amount of vibration data that is required to estimate the Time\nDomain Average of a gear vibration signal. Two models for estimating the time\ndomain average of a gear vibration signal are proposed. The models are tested\non data from an accelerated gear life test rig. Experimental results indicate\nthat the required data for calculating the Time Domain Average of a gear\nvibration signal can be reduced by up to 75% when the proposed models are\nimplemented.\n","versions":[{"version":"v1","created":"Fri, 11 May 2007 15:49:40 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Mdlazi","L.",""],["Stander","C. J.",""],["Heyns","P. S.",""],["Marwala","T.",""]]}
{"id":"0705.1886","submitter":"Francoise Armand","authors":"Michel Crampes (LGI2P), Sylvie Ranwez (LGI2P)","title":"Ontology-Supported and Ontology-Driven Conceptual Navigation on the\n  World Wide Web","comments":null,"journal-ref":"Proceedings Hypertext 2000 (2000) 80","doi":null,"report-no":null,"categories":"cs.IR","license":null,"abstract":"  This paper presents the principles of ontology-supported and ontology-driven\nconceptual navigation. Conceptual navigation realizes the independence between\nresources and links to facilitate interoperability and reusability. An engine\nbuilds dynamic links, assembles resources under an argumentative scheme and\nallows optimization with a possible constraint, such as the user's available\ntime. Among several strategies, two are discussed in detail with examples of\napplications. On the one hand, conceptual specifications for linking and\nassembling are embedded in the resource meta-description with the support of\nthe ontology of the domain to facilitate meta-communication. Resources are like\nagents looking for conceptual acquaintances with intention. On the other hand,\nthe domain ontology and an argumentative ontology drive the linking and\nassembling strategies.\n","versions":[{"version":"v1","created":"Mon, 14 May 2007 08:19:28 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Crampes","Michel","","LGI2P"],["Ranwez","Sylvie","","LGI2P"]]}
{"id":"0705.1999","submitter":"Camilla Schwind","authors":"Camilla Schwind (LIF)","title":"A first-order Temporal Logic for Actions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LO","license":null,"abstract":"  We present a multi-modal action logic with first-order modalities, which\ncontain terms which can be unified with the terms inside the subsequent\nformulas and which can be quantified. This makes it possible to handle\nsimultaneously time and states. We discuss applications of this language to\naction theory where it is possible to express many temporal aspects of actions,\nas for example, beginning, end, time points, delayed preconditions and results,\nduration and many others. We present tableaux rules for a decidable fragment of\nthis logic.\n","versions":[{"version":"v1","created":"Mon, 14 May 2007 18:36:25 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Schwind","Camilla","","LIF"]]}
{"id":"0705.2011","submitter":"Alex Graves","authors":"Alex Graves, Santiago Fernandez, Juergen Schmidhuber","title":"Multi-Dimensional Recurrent Neural Networks","comments":"10 pages, 10 figures","journal-ref":null,"doi":null,"report-no":"04-07","categories":"cs.AI cs.CV","license":null,"abstract":"  Recurrent neural networks (RNNs) have proved effective at one dimensional\nsequence learning tasks, such as speech and online handwriting recognition.\nSome of the properties that make RNNs suitable for such tasks, for example\nrobustness to input warping, and the ability to access contextual information,\nare also desirable in multidimensional domains. However, there has so far been\nno direct way of applying RNNs to data with more than one spatio-temporal\ndimension. This paper introduces multi-dimensional recurrent neural networks\n(MDRNNs), thereby extending the potential applicability of RNNs to vision,\nvideo processing, medical imaging and many other areas, while avoiding the\nscaling problems that have plagued other multi-dimensional models. Experimental\nresults are provided for two image segmentation tasks.\n","versions":[{"version":"v1","created":"Mon, 14 May 2007 19:49:56 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Graves","Alex",""],["Fernandez","Santiago",""],["Schmidhuber","Juergen",""]]}
{"id":"0705.2106","submitter":"Finn {\\AA}rup Nielsen","authors":"Finn Aarup Nielsen","title":"Scientific citations in Wikipedia","comments":"5 pages, 2 figures","journal-ref":"First Monday, 12(8), 2007 August","doi":null,"report-no":null,"categories":"cs.DL cs.IR","license":null,"abstract":"  The Internet-based encyclopaedia Wikipedia has grown to become one of the\nmost visited web-sites on the Internet. However, critics have questioned the\nquality of entries, and an empirical study has shown Wikipedia to contain\nerrors in a 2005 sample of science entries. Biased coverage and lack of sources\nare among the \"Wikipedia risks\". The present work describes a simple assessment\nof these aspects by examining the outbound links from Wikipedia articles to\narticles in scientific journals with a comparison against journal statistics\nfrom Journal Citation Reports such as impact factors. The results show an\nincreasing use of structured citation markup and good agreement with the\ncitation pattern seen in the scientific literature though with a slight\ntendency to cite articles in high-impact journals such as Nature and Science.\nThese results increase confidence in Wikipedia as an good information organizer\nfor science in general.\n","versions":[{"version":"v1","created":"Tue, 15 May 2007 09:42:30 GMT"}],"update_date":"2011-01-04","authors_parsed":[["Nielsen","Finn Aarup",""]]}
{"id":"0705.2235","submitter":"Tshilidzi Marwala","authors":"S. Chakraverty, T. Marwala, Pallavi Gupta and Thando Tettey","title":"Response Prediction of Structural System Subject to Earthquake Motions\n  using Artificial Neural Network","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper uses Artificial Neural Network (ANN) models to compute response of\nstructural system subject to Indian earthquakes at Chamoli and Uttarkashi\nground motion data. The system is first trained for a single real earthquake\ndata. The trained ANN architecture is then used to simulate earthquakes with\nvarious intensities and it was found that the predicted responses given by ANN\nmodel are accurate for practical purposes. When the ANN is trained by a part of\nthe ground motion data, it can also identify the responses of the structural\nsystem well. In this way the safeness of the structural systems may be\npredicted in case of future earthquakes without waiting for the earthquake to\noccur for the lessons. Time period and the corresponding maximum response of\nthe building for an earthquake has been evaluated, which is again trained to\npredict the maximum response of the building at different time periods. The\ntrained time period versus maximum response ANN model is also tested for real\nearthquake data of other place, which was not used in the training and was\nfound to be in good agreement.\n","versions":[{"version":"v1","created":"Tue, 15 May 2007 20:29:06 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Chakraverty","S.",""],["Marwala","T.",""],["Gupta","Pallavi",""],["Tettey","Thando",""]]}
{"id":"0705.2236","submitter":"Tshilidzi Marwala","authors":"Tshilidzi Marwala, Thando Tettey and Snehashish Chakraverty","title":"Fault Classification using Pseudomodal Energies and Neuro-fuzzy\n  modelling","comments":"8 pages, In Proceedings of the Asia-Pacific Workshop on Structural\n  Health Monitoring, Yokohama, Japan, 2006","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper presents a fault classification method which makes use of a\nTakagi-Sugeno neuro-fuzzy model and Pseudomodal energies calculated from the\nvibration signals of cylindrical shells. The calculation of Pseudomodal\nEnergies, for the purposes of condition monitoring, has previously been found\nto be an accurate method of extracting features from vibration signals. This\ncalculation is therefore used to extract features from vibration signals\nobtained from a diverse population of cylindrical shells. Some of the cylinders\nin the population have faults in different substructures. The pseudomodal\nenergies calculated from the vibration signals are then used as inputs to a\nneuro-fuzzy model. A leave-one-out cross-validation process is used to test the\nperformance of the model. It is found that the neuro-fuzzy model is able to\nclassify faults with an accuracy of 91.62%, which is higher than the previously\nused multilayer perceptron.\n","versions":[{"version":"v1","created":"Tue, 15 May 2007 20:34:05 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Marwala","Tshilidzi",""],["Tettey","Thando",""],["Chakraverty","Snehashish",""]]}
{"id":"0705.2305","submitter":"Tshilidzi Marwala","authors":"Sizwe M. Dhlamini, Tshilidzi Marwala, and Thokozani Majozi","title":"Fuzzy and Multilayer Perceptron for Evaluation of HV Bushings","comments":"7 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.NE","license":null,"abstract":"  The work proposes the application of fuzzy set theory (FST) to diagnose the\ncondition of high voltage bushings. The diagnosis uses dissolved gas analysis\n(DGA) data from bushings based on IEC60599 and IEEE C57-104 criteria for oil\nimpregnated paper (OIP) bushings. FST and neural networks are compared in terms\nof accuracy and computational efficiency. Both FST and NN simulations were able\nto diagnose the bushings condition with 10% error. By using fuzzy theory, the\nmaintenance department can classify bushings and know the extent of degradation\nin the component.\n","versions":[{"version":"v1","created":"Wed, 16 May 2007 09:06:19 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Dhlamini","Sizwe M.",""],["Marwala","Tshilidzi",""],["Majozi","Thokozani",""]]}
{"id":"0705.2307","submitter":"Tshilidzi Marwala","authors":"Bradley van Aardt, Tshilidzi Marwala","title":"A Study in a Hybrid Centralised-Swarm Agent Community","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  This paper describes a systems architecture for a hybrid Centralised/Swarm\nbased multi-agent system. The issue of local goal assignment for agents is\ninvestigated through the use of a global agent which teaches the agents\nresponses to given situations. We implement a test problem in the form of a\nPursuit game, where the Multi-Agent system is a set of captor agents. The\nagents learn solutions to certain board positions from the global agent if they\nare unable to find a solution. The captor agents learn through the use of\nmulti-layer perceptron neural networks. The global agent is able to solve board\npositions through the use of a Genetic Algorithm. The cooperation between\nagents and the results of the simulation are discussed here. .\n","versions":[{"version":"v1","created":"Wed, 16 May 2007 09:12:09 GMT"}],"update_date":"2007-05-23","authors_parsed":[["van Aardt","Bradley",""],["Marwala","Tshilidzi",""]]}
{"id":"0705.2310","submitter":"Tshilidzi Marwala","authors":"C.B. Vilakazi, T. Marwala, P. Mautla and E. Moloto","title":"On-Line Condition Monitoring using Computational Intelligence","comments":"8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper presents bushing condition monitoring frameworks that use\nmulti-layer perceptrons (MLP), radial basis functions (RBF) and support vector\nmachines (SVM) classifiers. The first level of the framework determines if the\nbushing is faulty or not while the second level determines the type of fault.\nThe diagnostic gases in the bushings are analyzed using the dissolve gas\nanalysis. MLP gives superior performance in terms of accuracy and training time\nthan SVM and RBF. In addition, an on-line bushing condition monitoring\napproach, which is able to adapt to newly acquired data are introduced. This\napproach is able to accommodate new classes that are introduced by incoming\ndata and is implemented using an incremental learning algorithm that uses MLP.\nThe testing results improved from 67.5% to 95.8% as new data were introduced\nand the testing results improved from 60% to 95.3% as new conditions were\nintroduced. On average the confidence value of the framework on its decision\nwas 0.92.\n","versions":[{"version":"v1","created":"Wed, 16 May 2007 09:19:00 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Vilakazi","C. B.",""],["Marwala","T.",""],["Mautla","P.",""],["Moloto","E.",""]]}
{"id":"0705.2318","submitter":"Seiji Miyoshi","authors":"Hideto Utsumi, Seiji Miyoshi, Masato Okada","title":"Statistical Mechanics of Nonlinear On-line Learning for Ensemble\n  Teachers","comments":"13 pages, 9 figures","journal-ref":null,"doi":"10.1143/JPSJ.76.114001","report-no":null,"categories":"cs.LG cond-mat.dis-nn","license":null,"abstract":"  We analyze the generalization performance of a student in a model composed of\nnonlinear perceptrons: a true teacher, ensemble teachers, and the student. We\ncalculate the generalization error of the student analytically or numerically\nusing statistical mechanics in the framework of on-line learning. We treat two\nwell-known learning rules: Hebbian learning and perceptron learning. As a\nresult, it is proven that the nonlinear model shows qualitatively different\nbehaviors from the linear model. Moreover, it is clarified that Hebbian\nlearning and perceptron learning show qualitatively different behaviors from\neach other. In Hebbian learning, we can analytically obtain the solutions. In\nthis case, the generalization error monotonically decreases. The steady value\nof the generalization error is independent of the learning rate. The larger the\nnumber of teachers is and the more variety the ensemble teachers have, the\nsmaller the generalization error is. In perceptron learning, we have to\nnumerically obtain the solutions. In this case, the dynamical behaviors of the\ngeneralization error are non-monotonic. The smaller the learning rate is, the\nlarger the number of teachers is; and the more variety the ensemble teachers\nhave, the smaller the minimum value of the generalization error is.\n","versions":[{"version":"v1","created":"Wed, 16 May 2007 09:58:39 GMT"}],"update_date":"2009-11-13","authors_parsed":[["Utsumi","Hideto",""],["Miyoshi","Seiji",""],["Okada","Masato",""]]}
{"id":"0705.2485","submitter":"Bodie Crossingham","authors":"Bodie Crossingham and Tshilidzi Marwala","title":"Using Genetic Algorithms to Optimise Rough Set Partition Sizes for HIV\n  Data Analysis","comments":"10 pages, 1 figure, Update Bibliography","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI q-bio.QM","license":null,"abstract":"  In this paper, we present a method to optimise rough set partition sizes, to\nwhich rule extraction is performed on HIV data. The genetic algorithm\noptimisation technique is used to determine the partition sizes of a rough set\nin order to maximise the rough sets prediction accuracy. The proposed method is\ntested on a set of demographic properties of individuals obtained from the\nSouth African antenatal survey. Six demographic variables were used in the\nanalysis, these variables are; race, age of mother, education, gravidity,\nparity, and age of father, with the outcome or decision being either HIV\npositive or negative. Rough set theory is chosen based on the fact that it is\neasy to interpret the extracted rules. The prediction accuracy of equal width\nbin partitioning is 57.7% while the accuracy achieved after optimising the\npartitions is 72.8%. Several other methods have been used to analyse the HIV\ndata and their results are stated and compared to that of rough set theory\n(RST).\n","versions":[{"version":"v1","created":"Thu, 17 May 2007 07:02:23 GMT"}],"update_date":"2007-06-25","authors_parsed":[["Crossingham","Bodie",""],["Marwala","Tshilidzi",""]]}
{"id":"0705.2516","submitter":"Tshilidzi Marwala","authors":"Sizwe M. Dhlamini*, Fulufhelo V. Nelwamondo**, Tshilidzi Marwala**","title":"Condition Monitoring of HV Bushings in the Presence of Missing Data\n  Using Evolutionary Computing","comments":"7 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  The work proposes the application of neural networks with particle swarm\noptimisation (PSO) and genetic algorithms (GA) to compensate for missing data\nin classifying high voltage bushings. The classification is done using DGA data\nfrom 60966 bushings based on IEEEc57.104, IEC599 and IEEE production rates\nmethods for oil impregnated paper (OIP) bushings. PSO and GA were compared in\nterms of accuracy and computational efficiency. Both GA and PSO simulations\nwere able to estimate missing data values to an average 95% accuracy when only\none variable was missing. However PSO rapidly deteriorated to 66% accuracy with\ntwo variables missing simultaneously, compared to 84% for GA. The data\nestimated using GA was found to classify the conditions of bushings than the\nPSO.\n","versions":[{"version":"v1","created":"Thu, 17 May 2007 11:33:34 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Dhlamini*","Sizwe M.",""],["Nelwamondo**","Fulufhelo V.",""],["Marwala**","Tshilidzi",""]]}
{"id":"0705.2765","submitter":"Rustem Takhanov","authors":"Rustem Takhanov","title":"On the monotonization of the training set","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":null,"abstract":"  We consider the problem of minimal correction of the training set to make it\nconsistent with monotonic constraints. This problem arises during analysis of\ndata sets via techniques that require monotone data. We show that this problem\nis NP-hard in general and is equivalent to finding a maximal independent set in\nspecial orgraphs. Practically important cases of that problem considered in\ndetail. These are the cases when a partial order given on the replies set is a\ntotal order or has a dimension 2. We show that the second case can be reduced\nto maximization of a quadratic convex function on a convex set. For this case\nwe construct an approximate polynomial algorithm based on convex optimization.\n","versions":[{"version":"v1","created":"Fri, 18 May 2007 19:44:19 GMT"}],"update_date":"2007-05-23","authors_parsed":[["Takhanov","Rustem",""]]}
{"id":"0705.3360","submitter":"Kyriakos Sgarbas","authors":"Kyriakos N. Sgarbas","title":"The Road to Quantum Artificial Intelligence","comments":"9 pages. Presented at PCI-2007: 11th Panhellenic Conference in\n  Informatics, 18-20 May 2007, Patras, Greece","journal-ref":"In: T.S.Papatheodorou, D.N.Christodoulakis and N.N.Karanikolas\n  (eds), \"Current Trends in Informatics\", Vol.A, pp.469-477, New Technologies\n  Publications, Athens, 2007 (SET 978-960-89784-0-9)","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper overviews the basic principles and recent advances in the emerging\nfield of Quantum Computation (QC), highlighting its potential application to\nArtificial Intelligence (AI). The paper provides a very brief introduction to\nbasic QC issues like quantum registers, quantum gates and quantum algorithms\nand then it presents references, ideas and research guidelines on how QC can be\nused to deal with some basic AI problems, such as search and pattern matching,\nas soon as quantum computers become widely available.\n","versions":[{"version":"v1","created":"Wed, 23 May 2007 12:31:47 GMT"}],"update_date":"2007-05-24","authors_parsed":[["Sgarbas","Kyriakos N.",""]]}
{"id":"0705.3561","submitter":"Lucas Bordeaux","authors":"Lucas Bordeaux, Marco Cadoli, Toni Mancini","title":"Generalizing Consistency and other Constraint Properties to Quantified\n  Constraints","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.AI","license":null,"abstract":"  Quantified constraints and Quantified Boolean Formulae are typically much\nmore difficult to reason with than classical constraints, because quantifier\nalternation makes the usual notion of solution inappropriate. As a consequence,\nbasic properties of Constraint Satisfaction Problems (CSP), such as consistency\nor substitutability, are not completely understood in the quantified case.\nThese properties are important because they are the basis of most of the\nreasoning methods used to solve classical (existentially quantified)\nconstraints, and one would like to benefit from similar reasoning methods in\nthe resolution of quantified constraints. In this paper, we show that most of\nthe properties that are used by solvers for CSP can be generalized to\nquantified CSP. This requires a re-thinking of a number of basic concepts; in\nparticular, we propose a notion of outcome that generalizes the classical\nnotion of solution and on which all definitions are based. We propose a\nsystematic study of the relations which hold between these properties, as well\nas complexity results regarding the decision of these properties. Finally, and\nsince these problems are typically intractable, we generalize the approach used\nin CSP and propose weaker, easier to check notions based on locality, which\nallow to detect these properties incompletely but in polynomial time.\n","versions":[{"version":"v1","created":"Thu, 24 May 2007 11:27:55 GMT"}],"update_date":"2007-05-25","authors_parsed":[["Bordeaux","Lucas",""],["Cadoli","Marco",""],["Mancini","Toni",""]]}
{"id":"0705.3766","submitter":"Anton Eremeev","authors":"Anton Eremeev","title":"On complexity of optimized crossover for binary representations","comments":"Dagstuhl Seminar 06061 \"Theory of Evolutionary Algorithms\", 2006","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":null,"abstract":"  We consider the computational complexity of producing the best possible\noffspring in a crossover, given two solutions of the parents. The crossover\noperators are studied on the class of Boolean linear programming problems,\nwhere the Boolean vector of variables is used as the solution representation.\nBy means of efficient reductions of the optimized gene transmitting crossover\nproblems (OGTC) we show the polynomial solvability of the OGTC for the maximum\nweight set packing problem, the minimum weight set partition problem and for\none of the versions of the simple plant location problem. We study a connection\nbetween the OGTC for linear Boolean programming problem and the maximum weight\nindependent set problem on 2-colorable hypergraph and prove the NP-hardness of\nseveral special cases of the OGTC problem in Boolean linear programming.\n","versions":[{"version":"v1","created":"Fri, 25 May 2007 13:07:18 GMT"}],"update_date":"2007-05-28","authors_parsed":[["Eremeev","Anton",""]]}
{"id":"0705.4302","submitter":"Jens Oehlschl\\\"agel","authors":"Jens Oehlschl\\\"agel","title":"Truecluster matching","comments":"15 pages, 2 figures. Details the matching needed for \"Truecluster:\n  robust scalable clustering with model selection\" but can also be used in\n  different contexts","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Cluster matching by permuting cluster labels is important in many clustering\ncontexts such as cluster validation and cluster ensemble techniques. The\nclassic approach is to minimize the euclidean distance between two cluster\nsolutions which induces inappropriate stability in certain settings. Therefore,\nwe present the truematch algorithm that introduces two improvements best\nexplained in the crisp case. First, instead of maximizing the trace of the\ncluster crosstable, we propose to maximize a chi-square transformation of this\ncrosstable. Thus, the trace will not be dominated by the cells with the largest\ncounts but by the cells with the most non-random observations, taking into\naccount the marginals. Second, we suggest a probabilistic component in order to\nbreak ties and to make the matching algorithm truly random on random data. The\ntruematch algorithm is designed as a building block of the truecluster\nframework and scales in polynomial time. First simulation results confirm that\nthe truematch algorithm gives more consistent truecluster results for unequal\ncluster sizes. Free R software is available.\n","versions":[{"version":"v1","created":"Tue, 29 May 2007 21:52:17 GMT"}],"update_date":"2007-05-31","authors_parsed":[["Oehlschl\u00e4gel","Jens",""]]}
{"id":"0705.4485","submitter":"Edoardo Airoldi","authors":"Edoardo M Airoldi, David M Blei, Stephen E Fienberg, Eric P Xing","title":"Mixed membership stochastic blockmodels","comments":"46 pages, 14 figures, 3 tables","journal-ref":"Journal of Machine Learning Research, 9, 1981-2014.","doi":null,"report-no":null,"categories":"stat.ME cs.LG math.ST physics.soc-ph stat.ML stat.TH","license":null,"abstract":"  Observations consisting of measurements on relationships for pairs of objects\narise in many settings, such as protein interaction and gene regulatory\nnetworks, collections of author-recipient email, and social networks. Analyzing\nsuch data with probabilisic models can be delicate because the simple\nexchangeability assumptions underlying many boilerplate models no longer hold.\nIn this paper, we describe a latent variable model of such data called the\nmixed membership stochastic blockmodel. This model extends blockmodels for\nrelational data to ones which capture mixed membership latent relational\nstructure, thus providing an object-specific low-dimensional representation. We\ndevelop a general variational inference algorithm for fast approximate\nposterior inference. We explore applications to social and protein interaction\nnetworks.\n","versions":[{"version":"v1","created":"Wed, 30 May 2007 23:22:59 GMT"}],"update_date":"2010-02-22","authors_parsed":[["Airoldi","Edoardo M",""],["Blei","David M",""],["Fienberg","Stephen E",""],["Xing","Eric P",""]]}
{"id":"0705.4566","submitter":"Bastian Wemmenhove","authors":"Bastian Wemmenhove and Bert Kappen","title":"Loop corrections for message passing algorithms in continuous variable\n  models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":null,"abstract":"  In this paper we derive the equations for Loop Corrected Belief Propagation\non a continuous variable Gaussian model. Using the exactness of the averages\nfor belief propagation for Gaussian models, a different way of obtaining the\ncovariances is found, based on Belief Propagation on cavity graphs. We discuss\nthe relation of this loop correction algorithm to Expectation Propagation\nalgorithms for the case in which the model is no longer Gaussian, but slightly\nperturbed by nonlinear terms.\n","versions":[{"version":"v1","created":"Thu, 31 May 2007 10:35:07 GMT"}],"update_date":"2007-06-01","authors_parsed":[["Wemmenhove","Bastian",""],["Kappen","Bert",""]]}
{"id":"0705.4584","submitter":"Stefan Johansson","authors":"Magnus Boman and Stefan J. Johansson","title":"Modeling Epidemic Spread in Synthetic Populations - Virtual Plagues in\n  Massively Multiplayer Online Games","comments":"Accepted for presentation at Digital Games Research Association\n  (DiGRA) conference in Tokyo in September 2007. All comments to the authors\n  (mail addresses are in the paper) are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.AI cs.MA","license":null,"abstract":"  A virtual plague is a process in which a behavior-affecting property spreads\namong characters in a Massively Multiplayer Online Game (MMOG). The MMOG\nindividuals constitute a synthetic population, and the game can be seen as a\nform of interactive executable model for studying disease spread, albeit of a\nvery special kind. To a game developer maintaining an MMOG, recognizing,\nmonitoring, and ultimately controlling a virtual plague is important,\nregardless of how it was initiated. The prospect of using tools, methods and\ntheory from the field of epidemiology to do this seems natural and appealing.\nWe will address the feasibility of such a prospect, first by considering some\nbasic measures used in epidemiology, then by pointing out the differences\nbetween real world epidemics and virtual plagues. We also suggest directions\nfor MMOG developer control through epidemiological modeling. Our aim is\nunderstanding the properties of virtual plagues, rather than trying to\neliminate them or mitigate their effects, as would be in the case of real\ninfectious disease.\n","versions":[{"version":"v1","created":"Thu, 31 May 2007 12:15:05 GMT"}],"update_date":"2007-06-01","authors_parsed":[["Boman","Magnus",""],["Johansson","Stefan J.",""]]}
{"id":"0705.4606","submitter":"Marco Pellegrini","authors":"Filippo Geraci and Marco Pellegrini","title":"Dynamic User-Defined Similarity Searching in Semi-Structured Text\n  Retrieval","comments":"Submitted to Spire 2007","journal-ref":null,"doi":null,"report-no":"IIT TR-07/2007","categories":"cs.IR cs.DS","license":null,"abstract":"  Modern text retrieval systems often provide a similarity search utility, that\nallows the user to find efficiently a fixed number k of documents in the data\nset that are most similar to a given query (here a query is either a simple\nsequence of keywords or the identifier of a full document found in previous\nsearches that is considered of interest). We consider the case of a textual\ndatabase made of semi-structured documents. Each field, in turns, is modelled\nwith a specific vector space. The problem is more complex when we also allow\neach such vector space to have an associated user-defined dynamic weight that\ninfluences its contribution to the overall dynamic aggregated and weighted\nsimilarity. This dynamic problem has been tackled in a recent paper by\nSingitham et al. in in VLDB 2004. Their proposed solution, which we take as\nbaseline, is a variant of the cluster-pruning technique that has the potential\nfor scaling to very large corpora of documents, and is far more efficient than\nthe naive exhaustive search. We devise an alternative way of embedding weights\nin the data structure, coupled with a non-trivial application of a clustering\nalgorithm based on the furthest point first heuristic for the metric k-center\nproblem. The validity of our approach is demonstrated experimentally by showing\nsignificant performance improvements over the scheme proposed in Singitham et\nal. in VLDB 2004. We improve significantly tradeoffs between query time and\noutput quality with respect to the baseline method in Singitham et al. in in\nVLDB 2004, and also with respect to a novel method by Chierichetti et al. to\nappear in ACM PODS 2007. We also speed up the pre-processing time by a factor\nat least thirty.\n","versions":[{"version":"v1","created":"Thu, 31 May 2007 13:46:39 GMT"}],"update_date":"2007-06-01","authors_parsed":[["Geraci","Filippo",""],["Pellegrini","Marco",""]]}
{"id":"0706.0022","submitter":"Marko Antonio Rodriguez","authors":"Marko A. Rodriguez and Johan Bollen","title":"Modeling Computations in a Semantic Network","comments":"project website: http://neno.lanl.gov","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Semantic network research has seen a resurgence from its early history in the\ncognitive sciences with the inception of the Semantic Web initiative. The\nSemantic Web effort has brought forth an array of technologies that support the\nencoding, storage, and querying of the semantic network data structure at the\nworld stage. Currently, the popular conception of the Semantic Web is that of a\ndata modeling medium where real and conceptual entities are related in\nsemantically meaningful ways. However, new models have emerged that explicitly\nencode procedural information within the semantic network substrate. With these\nnew technologies, the Semantic Web has evolved from a data modeling medium to a\ncomputational medium. This article provides a classification of existing\ncomputational modeling efforts and the requirements of supporting technologies\nthat will aid in the further growth of this burgeoning domain.\n","versions":[{"version":"v1","created":"Thu, 31 May 2007 21:56:25 GMT"}],"update_date":"2021-08-23","authors_parsed":[["Rodriguez","Marko A.",""],["Bollen","Johan",""]]}
{"id":"0706.0465","submitter":"Donald Sofge","authors":"D. A. Sofge","title":"Virtual Sensor Based Fault Detection and Classification on a Plasma Etch\n  Reactor","comments":"7 pages","journal-ref":"D. Sofge, \"Virtual Sensor Based Fault Detection and Classification\n  on a Plasma Etch Reactor,\" The 2nd Joint Mexico-US Int'l. Workshop on Neural\n  Networks and Neurocontrol (poster), 1997","doi":null,"report-no":null,"categories":"cs.AI cs.CV","license":null,"abstract":"  The SEMATECH sponsored J-88-E project teaming Texas Instruments with\nNeuroDyne (et al.) focused on Fault Detection and Classification (FDC) on a Lam\n9600 aluminum plasma etch reactor, used in the process of semiconductor\nfabrication. Fault classification was accomplished by implementing a series of\nvirtual sensor models which used data from real sensors (Lam Station sensors,\nOptical Emission Spectroscopy, and RF Monitoring) to predict recipe setpoints\nand wafer state characteristics. Fault detection and classification were\nperformed by comparing predicted recipe and wafer state values with expected\nvalues. Models utilized include linear PLS, Polynomial PLS, and Neural Network\nPLS. Prediction of recipe setpoints based upon sensor data provides a\ncapability for cross-checking that the machine is maintaining the desired\nsetpoints. Wafer state characteristics such as Line Width Reduction and\nRemaining Oxide were estimated on-line using these same process sensors (Lam,\nOES, RFM). Wafer-to-wafer measurement of these characteristics in a production\nsetting (where typically this information may be only sparsely available, if at\nall, after batch processing runs with numerous wafers have been completed)\nwould provide important information to the operator that the process is or is\nnot producing wafers within acceptable bounds of product quality. Production\nyield is increased, and correspondingly per unit cost is reduced, by providing\nthe operator with the opportunity to adjust the process or machine before\netching more wafers.\n","versions":[{"version":"v1","created":"Mon, 4 Jun 2007 15:55:27 GMT"}],"update_date":"2007-06-05","authors_parsed":[["Sofge","D. A.",""]]}
{"id":"0706.0585","submitter":"Zhendong Zhao","authors":"Zhendong Zhao, Lei Yuan, Yuxuan Wang, Forrest Sheng Bao, Shunyi Zhang\n  Yanfei Sun","title":"A Novel Model of Working Set Selection for SMO Decomposition Methods","comments":"8 pages, 12 figures, it was submitted to IEEE International\n  conference of Tools on Artificial Intelligence","journal-ref":null,"doi":"10.1109/ICTAI.2007.99","report-no":null,"categories":"cs.LG cs.AI","license":null,"abstract":"  In the process of training Support Vector Machines (SVMs) by decomposition\nmethods, working set selection is an important technique, and some exciting\nschemes were employed into this field. To improve working set selection, we\npropose a new model for working set selection in sequential minimal\noptimization (SMO) decomposition methods. In this model, it selects B as\nworking set without reselection. Some properties are given by simple proof, and\nexperiments demonstrate that the proposed method is in general faster than\nexisting methods.\n","versions":[{"version":"v1","created":"Tue, 5 Jun 2007 05:55:07 GMT"}],"update_date":"2016-11-15","authors_parsed":[["Zhao","Zhendong",""],["Yuan","Lei",""],["Wang","Yuxuan",""],["Bao","Forrest Sheng",""],["Sun","Shunyi Zhang Yanfei",""]]}
{"id":"0706.1001","submitter":"Krzysztof R. Apt","authors":"Krzysztof R. Apt","title":"Epistemic Analysis of Strategic Games with Arbitrary Strategy Sets","comments":"8 pages Proc. of the 11th Conference on Theoretical Aspects of\n  Rationality and Knowledge (TARK XI), 2007. To appear","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.AI","license":null,"abstract":"  We provide here an epistemic analysis of arbitrary strategic games based on\nthe possibility correspondences. Such an analysis calls for the use of\ntransfinite iterations of the corresponding operators. Our approach is based on\nTarski's Fixpoint Theorem and applies both to the notions of rationalizability\nand the iterated elimination of strictly dominated strategies.\n","versions":[{"version":"v1","created":"Thu, 7 Jun 2007 12:57:21 GMT"}],"update_date":"2007-06-08","authors_parsed":[["Apt","Krzysztof R.",""]]}
{"id":"0706.1137","submitter":"Thierry Poibeau","authors":"Amanda Bouffier (LIPN), Thierry Poibeau (LIPN)","title":"Automatically Restructuring Practice Guidelines using the GEM DTD","comments":null,"journal-ref":"Proceedings of Biomedical Natural Language Processing (BioNLP)\n  (2007) -","doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  This paper describes a system capable of semi-automatically filling an XML\ntemplate from free texts in the clinical domain (practice guidelines). The XML\ntemplate includes semantic information not explicitly encoded in the text\n(pairs of conditions and actions/recommendations). Therefore, there is a need\nto compute the exact scope of conditions over text sequences expressing the\nrequired actions. We present a system developed for this task. We show that it\nyields good performance when applied to the analysis of French practice\nguidelines.\n","versions":[{"version":"v1","created":"Fri, 8 Jun 2007 15:39:49 GMT"}],"update_date":"2007-06-11","authors_parsed":[["Bouffier","Amanda","","LIPN"],["Poibeau","Thierry","","LIPN"]]}
{"id":"0706.1179","submitter":"Hichem Geryville","authors":"Hichem Geryville (LIESP), Abdelaziz Bouras (LIESP), Yacine Ouzrout\n  (LIESP), Nikolaos Sapidis","title":"Collaborative product and process model: Multiple Viewpoints approach","comments":"391-398","journal-ref":"Innovative Products and Services through Collaborative Networks\n  (2006) 542","doi":"10.1000/ISBN0-85358-228-9","report-no":null,"categories":"cs.OH cs.IR","license":null,"abstract":"  The design and development of complex products invariably involves many\nactors who have different points of view on the problem they are addressing,\nthe product being developed, and the process by which it is being developed.\nThe actors' viewpoints approach was designed to provide an organisational\nframework in which these different perspectives or points of views, and their\nrelationships, could be explicitly gathered and formatted (by actor activity's\nfocus). The approach acknowledges the inevitability of multiple interpretation\nof product information as different views, promotes gathering of actors'\ninterests, and encourages retrieved adequate information while providing\nsupport for integration through PLM and/or SCM collaboration. In this paper, we\npresent our multiple viewpoints approach, and we illustrate it by an industrial\nexample on cyclone vessel product.\n","versions":[{"version":"v1","created":"Fri, 8 Jun 2007 13:09:13 GMT"}],"update_date":"2007-06-11","authors_parsed":[["Geryville","Hichem","","LIESP"],["Bouras","Abdelaziz","","LIESP"],["Ouzrout","Yacine","","LIESP"],["Sapidis","Nikolaos",""]]}
{"id":"0706.1290","submitter":"Sylviane Schwer","authors":"Sylviane R. Schwer (LIPN)","title":"Temporal Reasoning without Transitive Tables","comments":"rapport interne","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":null,"abstract":"  Representing and reasoning about qualitative temporal information is an\nessential part of many artificial intelligence tasks. Lots of models have been\nproposed in the litterature for representing such temporal information. All\nderive from a point-based or an interval-based framework. One fundamental\nreasoning task that arises in applications of these frameworks is given by the\nfollowing scheme: given possibly indefinite and incomplete knowledge of the\nbinary relationships between some temporal objects, find the consistent\nscenarii between all these objects. All these models require transitive tables\n-- or similarly inference rules-- for solving such tasks. We have defined an\nalternative model, S-languages - to represent qualitative temporal information,\nbased on the only two relations of \\emph{precedence} and \\emph{simultaneity}.\nIn this paper, we show how this model enables to avoid transitive tables or\ninference rules to handle this kind of problem.\n","versions":[{"version":"v1","created":"Sat, 9 Jun 2007 06:57:05 GMT"}],"update_date":"2007-06-12","authors_parsed":[["Schwer","Sylviane R.","","LIPN"]]}
